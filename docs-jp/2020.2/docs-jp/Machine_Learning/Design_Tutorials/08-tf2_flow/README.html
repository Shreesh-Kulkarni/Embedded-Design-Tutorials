


<!DOCTYPE HTML>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
	<head>
		<meta charset="utf-8">
		
		<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>
		<link rel="stylesheet" href="https://static.cloud.coveo.com/searchui/v2.4382/css/CoveoFullSearch.css"/>
		<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
		<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
		<meta name="description"/>
		<meta name="keywords"/>
		<meta property="og:title" content=""/>
		<meta property="og:description"/>
		<!-- favicon -->
		<link rel="icon" type="image/vnd.microsoft.icon" href="../../../_static/favicon.ico"/>
		<link rel="shortcut icon" type="image/vnd.microsoft.icon" href="../../../_static/favicon.ico"/>
		<!-- Fonts -->
		<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet" type="text/css"/>

  
  
  
  

  
      <script type="text/javascript" src="../../../_static/js/jquery.min.js"></script>
	  <script type="text/javascript" src="../../../_static/js/gtm.js"></script>
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/d3dd8c60ed.js"></script>
    <script type="text/javascript" src="../../../_static/js/common-ui-all.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/header-footer.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/jquery-ui.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/CoveoJsSearch.Lazy.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/linkid.js"></script>
    <script type="text/javascript" src="../../../_static/js/Searchbox.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/common-ui-all.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/header-footer.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/pro.min.css" media="all" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
	</head>
	<body>
		<div class="xilinx-bs3"/>
		<div class="root responsivegrid">
			<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 aem-Grid--large--16 aem-Grid--xlarge--16 aem-Grid--xxlarge--16 aem-Grid--xxxlarge--16 ">
				<div class="xilinxExperienceFragments experiencefragment aem-GridColumn aem-GridColumn--default--12">
					<div class="xf-content-height">
						<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 ">
							<div class="header parbase aem-GridColumn aem-GridColumn--default--12">
								<noindex>
									<header data-component="header">
										<nav class="navbar navbar-default aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid main-nav">
													<div class="row">
														<div class="col-xs-12">
															<div class="logo-column">
																<div class="logo">
																	<a href="https://www.xilinx.com/">
																	<img src="https://www.xilinx.com/etc.clientlibs/site/clientlibs/xilinx/all/resources/imgs/header/xilinx-header-logo.svg" title="Xilinx Inc"/>
																	</a>
																</div>
															</div>
															<div class="navbar-column">
																<div class="navbar navbar-collapse collapse" id="xilinx-main-menu">
																	<div class="mobile-search-container">
																		<div id="headerSearchBox" class="headerSearch"
																			data-component="header-search"
																			data-redirect-if-empty="false"
																			data-coveo-access-token="xxa237d4dd-f0aa-47fc-9baa-af9121851b33"
																			data-coveo-organization-id="xilinxcomprode2rjoqok">
																			<div class='coveo-search-section'>
																				<div class="CoveoAnalytics" data-search-hub="Site"></div>
																				<ul class="dropdown-menu options">
																					<li class="option" data-label="All" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-search-hub="Site">
																						<a href="#">
																						All</a>
																					</li>
																					<li data-label="Silicon Devices" data-action-link="https://www.xilinx.com//products/silicon-devices/si-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Silicon Devices</a>
																					</li>
																					<li data-label="Boards and Kits" data-action-link="https://www.xilinx.com//products/boards-and-kits/bk-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Boards and Kits</a>
																					</li>
																					<li data-label="Intellectual Property" data-action-link="https://www.xilinx.com//products/intellectual-property/ip-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Intellectual Property</a>
																					</li>
																					<li data-label="Support" class="option" data-action-link="https://www.xilinx.com/search/support-keyword-search.html" data-search-hub="Support">
																						<a href="#">
																						Support</a>
																						<ul>
																							<li data-label="Documentation" data-action-link="https://www.xilinx.com//support/documentation-navigation/documentation-keyword-search.html" data-search-hub="Document">
																								<a href="#">
																								Documentation</a>
																							</li>
																							<li data-label="Knowledge Base" data-action-link="https://www.xilinx.com//support/answer-navigation/answer-keyword-search.html" data-search-hub="AnswerRecord">
																								<a href="#">
																								Knowledge Base</a>
																							</li>
																							<li data-label="Community Forums" data-action-link="https://www.xilinx.com/search/forums-keyword-search.html" data-search-hub="Forums">
																								<a href="#">
																								Community Forums</a>
																							</li>
																						</ul>
																					</li>
																					<li data-label="Partners" data-action-link="https://www.xilinx.com//alliance/member-keyword-search.html" data-search-hub="Partner">
																						<a href="#">
																						Partners</a>
																					</li>
																					<li data-label="Videos" data-action-link="https://www.xilinx.com/video/video-keyword-search.html" data-search-hub="Video">
																						<a href="#">
																						Videos</a>
																					</li>
																					<li data-label="Press" data-action-link="https://www.xilinx.com/search/press-keyword-search.html" data-search-hub="Press">
																						<a href="#">
																						Press</a>
																					</li>
																				</ul>
																				<a href="#" class="btn dropdown-toggle value" data-toggle="dropdown"></a>
																				<div class="CoveoSearchbox" data-id="coveosearchbox" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-placeholder="Search Xilinx"></div>
																			</div>
																		</div>
																	</div>
																	<ul class="nav navbar-nav nav-justified">
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/applications.html">
																			Applications</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/products/silicon-devices.html">
																			Products</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://developer.xilinx.com/">
																			Developers</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/support.html">
																			Support</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/about/company-overview.html">
																			About</a>
																		</li>
																	</ul>
																</div>
															</div>
															<script type="text/javascript" src="../../../_static/js/gtm.js"></script>
															<!--<div class="mini-nav">
																<button type="button" data-function="xilinx-mobile-menu" id="nav-toggle" class="navbar-toggle collapsed visible-xs-block" aria-expanded="false">
																<span></span>
																<span></span>
																<span></span>
																<span></span>
																</button>
																<ul class="list-inline">
																	<li class="dropdown user-menu">
																		<button data-toggle="dropdown">
																		<span class="sr-only">Account</span>
																		<span class="fas fa-user"></span>
																		</button>
																		<ul class="dropdown-menu">
																			<li>
																				<a href="https://www.xilinx.com/myprofile/subscriptions.html">
																				My Account</a>
																			</li>
																			<li>
																				<a href="https://www.xilinx.com/registration/create-account.html">
																				Create Account</a>
																			</li>
																			<li>
																				<a href="https://www.xilinx.com/bin/protected/en/signout">
																				Sign Out</a>
																			</li>
																		</ul>
																	</li>
																	<li class="hidden-xs">
																		<button data-function="search-toggle">
																		<span class="sr-only">Search</span>
																		<span class="far fa-search"></span>
																		</button>
																	</li>
																</ul>
															</div>
															-->
															<div class="search-container">
																<div id="headerSearchBox" class="headerSearch"
																	data-component="header-search"
																	data-redirect-if-empty="false"
																	data-coveo-access-token="xxa237d4dd-f0aa-47fc-9baa-af9121851b33"
																	data-coveo-organization-id="xilinxcomprode2rjoqok">
																	<div class='coveo-search-section'>
																		<div class="CoveoAnalytics" data-search-hub="Site"></div>
																		<ul class="dropdown-menu options">
																			<li class="option" data-label="All" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-search-hub="Site">
																				<a href="#">
																				All</a>
																			</li>
																			<li data-label="Silicon Devices" data-action-link="https://www.xilinx.com/products/silicon-devices/si-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Silicon Devices</a>
																			</li>
																			<li data-label="Boards and Kits" data-action-link="https://www.xilinx.com/products/boards-and-kits/bk-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Boards and Kits</a>
																			</li>
																			<li data-label="Intellectual Property" data-action-link="https://www.xilinx.com/products/intellectual-property/ip-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Intellectual Property</a>
																			</li>
																			<li data-label="Support" class="option" data-action-link="https://www.xilinx.com/search/support-keyword-search.html" data-search-hub="Support">
																				<a href="#">
																				Support</a>
																				<ul>
																					<li data-label="Documentation" data-action-link="https://www.xilinx.com/support/documentation-navigation/documentation-keyword-search.html" data-search-hub="Document">
																						<a href="#">
																						Documentation</a>
																					</li>
																					<li data-label="Knowledge Base" data-action-link="https://www.xilinx.com/support/answer-navigation/answer-keyword-search.html" data-search-hub="AnswerRecord">
																						<a href="#">
																						Knowledge Base</a>
																					</li>
																					<li data-label="Community Forums" data-action-link="https://www.xilinx.com/search/forums-keyword-search.html" data-search-hub="Forums">
																						<a href="#">
																						Community Forums</a>
																					</li>
																				</ul>
																			</li>
																			<li data-label="Partners" data-action-link="https://www.xilinx.com/alliance/member-keyword-search.html" data-search-hub="Partner">
																				<a href="#">
																				Partners</a>
																			</li>
																			<li data-label="Videos" data-action-link="https://www.xilinx.com/video/video-keyword-search.html" data-search-hub="Video">
																				<a href="#">
																				Videos</a>
																			</li>
																			<li data-label="Press" data-action-link="https://www.xilinx.com/search/press-keyword-search.html" data-search-hub="Press">
																				<a href="#">
																				Press</a>
																			</li>
																		</ul>
																		<a href="#" class="btn dropdown-toggle value" data-toggle="dropdown"></a>
																		<div class="CoveoSearchbox" data-id="coveosearchbox" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-placeholder="Search Xilinx"></div>
																	</div>
																</div>
																<button data-function="search-toggle">
																<span class="sr-only">Search</span>
																<span class="far fa-times"></span>
																</button>
															</div>
														</div>
													</div>
												</div>
											</div>
										</nav>
									</header>
								</noindex>
							</div>
						</div>
					</div>
				</div>
				<div class="parsys aem-GridColumn--xxxlarge--none aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
						<div class="container-fluid">
							<div class="row">
							<div class="col-xs-12">
   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> Vitis チュートリアル
          

          
          </a>

          
            
            
              <div class="version">
                2020.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

      
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
            
            
            
              
            
            
              <p class="caption"><span class="caption-text">English version</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/master/docs/index.html">Master</a></li>
</ul>
<p class="caption"><span class="caption-text">入門</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis/README.html">Vitis フロー 101 チュートリアル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis_HLS/README.html">Vitis HLS の解析および最適化</a></li>
</ul>
<p class="caption"><span class="caption-text">機械学習 (英語版)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Introduction to Machine Learning with Vitis AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../README.html#design-tutorials">Design Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../README.html#feature-tutorials">Feature Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">アクセラレーション</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html">Vitis ハードウェア アクセラレータの概要</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html#id1">設計チュートリアル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html#id2">機能チュートリアル</a></li>
</ul>
<p class="caption"><span class="caption-text">AI エンジン開発 (英語版)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../AI_Engine_Development/README.html">Design Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../AI_Engine_Development/README.html#feature-tutorials">Feature Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">プラットフォーム作成チュートリアル</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/README.html">プラットフォームの作成</a></li>
</ul>
<p class="caption"><span class="caption-text">XRT および Vitis システム最適化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/README.html">設計チュートリアル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/README.html#id2">機能チュートリアル</a></li>
</ul>
<p class="caption"><span class="caption-text">バージョン</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/2020-1/docs/README.html">2020.1</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Xilinx/Vitis-Tutorials/blob/Vitis-Tutorials-2019.2-Hotfix1/README.md">2019.2</a></li>
</ul>

            
			
			<p class="caption"><span class="caption-text">This Page</span></p>
				<ul class="current">
				  <li class="toctree-l1"><a href="../../../_sources/Machine_Learning/Design_Tutorials/08-tf2_flow/README.md.txt"
						rel="nofollow">Show Source</a></li>
				</ul>
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Vitis チュートリアル</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Current status</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/Machine_Learning/Design_Tutorials/08-tf2_flow/README.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <!--
Copyright 2020 Xilinx Inc.
 
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0
 
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

Author: Mark Harvey, Xilinx Inc
--><table class="sphinxhide">
 <tr>
   <td align="center"><img src="https://www.xilinx.com/content/dam/xilinx/imgs/press/media-kits/corporate/xilinx-logo.png" width="30%"/><h1>Vitis AI Tutorials</h1>
  </td>
 </tr>
 <tr>
 <td align="center"><h1>TensorFlow2 and Vitis AI design flow</h1>
 </td>
 </tr>
</table><p>This tutorial shows you how to compile and run the same identical design and application code on a number of different Xilinx cards. The virtually seamless transition between Edge and Cloud is made possible by the Vitis™ AI RunTime (VART) which is common to all target platforms and its unified APIs.</p>
<div class="section" id="current-status">
<h1>Current status<a class="headerlink" href="#current-status" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Tested on ZCU102, Alveo U50</p></li>
<li><p>Tools used: TensorFlow2.3 &amp; Vitis AI 1.3</p></li>
<li><p>Dataset: <a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/data">Kaggle dogs-vs-cats</a></p></li>
<li><p>Network: Custom CNN</p></li>
</ul>
</div>
<div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>We will run the following steps:</p>
<ul class="simple">
<li><p>Download and preparation of the Kaggle dogs-vs-cats dataset. Conversion of images to TFRecords.</p></li>
<li><p>Training and evaluation of a custom CNN using TensorFlow’s built-in version of Keras.</p></li>
<li><p>Quantization of the floating-point model using the Xilinx® quantizer provided as part of Vitis AI.</p></li>
<li><p>Evaluation of the quantized model using the dogs-vs-cats test dataset.</p></li>
<li><p>Compilation of the quantized model for execution on the target boards.</p></li>
<li><p>Execution of the network on the target boards with the provided Python scripts.</p></li>
</ul>
<p>The complete flow and the tools used at each step is shown in the figure below:</p>
<p><img alt="Complete flow" src="../../../_images/fig1.png" /></p>
</div>
<div class="section" id="the-kaggle-dogs-vs-cats-dataset">
<h1>The Kaggle Dogs-vs-Cats Dataset<a class="headerlink" href="#the-kaggle-dogs-vs-cats-dataset" title="Permalink to this headline">¶</a></h1>
<p>The <a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/data">Kaggle dog-vs-cats dataset</a> consists of 25000 images of varying dimensions, divided into the two classes of <em>cat</em> and <em>dog</em>. Each image is intrinsically labelled or classified by its filename, for example the image with filename <em>cat.12.jpg</em> is obviously of class <em>cat</em>.</p>
<p>There is also a set of labelled images which were part of the original Kaggle dogs-vs-cats challenge, but we will ignore this set and only use the 25000 images that are contained in the train.zip archive.</p>
<p>The 25000 images are all resized to 200 x 250 pixels and then divided into one of the train, validation or test datasets. The size of 200 x 250 pixels was chosen after studying the distribution of the aspect ratios in the dataset and to keep training times reasonable.</p>
</div>
<div class="section" id="the-convolutional-neural-network">
<h1>The Convolutional Neural Network<a class="headerlink" href="#the-convolutional-neural-network" title="Permalink to this headline">¶</a></h1>
<p>The customcnn.py script uses the Keras Functional API to describe the simple CNN. It is a fully convolutional network and has no fully connected or dense layers. There are also no pooling layers—data reduction is achieved by using convolutional layers that have strides greater than one.</p>
<p>The CNN has deliberately been kept simple (so the expected prediction accuracy will not be much higher than approximately 95%. To reduce overfitting, batch normalization, dropout and L2 kernel regularization have been used.</p>
<p><img alt="Custom CNN architecture" src="../../../_images/fig2.png" /></p>
<p>The number of skip blocks and the number of filters used in each one is set by the ‘filters’ list argument - one skip block will be created for each element in the list.</p>
</div>
<div class="section" id="before-you-begin">
<h1>Before You Begin<a class="headerlink" href="#before-you-begin" title="Permalink to this headline">¶</a></h1>
<p>The host machine has several requirements that need to be met before we begin. You will need:</p>
<ul class="simple">
<li><p>An x86 host machine with a supported OS and the GPU version of the Vitis-AI docker installed - see <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/blob/master/docs/system_requirements">System Requirements</a>.</p></li>
<li><p>The host machine will require Docker to be installed and the Vitis-AI GPU docker image to be built - see <a class="reference external" href="https://github.com/Xilinx/Vitis-AI#getting-started">Getting Started</a>.</p></li>
<li><p>A GPU card suitable for ML training - a GPU with at least 8GB of memory is recommended.</p></li>
<li><p>If you plan to use the ZCU102 evaluation board, it should be prepared with the board image as per the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/tree/master/setup/mpsoc/VART#step2-setup-the-target">Setup the Target</a> instructions. Hints on how to connect the various cables to the ZCU102 are also available <a class="reference external" href="https://www.xilinx.com/html_docs/vitis_ai/1_3/installation.html#yjf1570690235238">here</a>.</p></li>
<li><p>For the Alveo U50, follow the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/tree/master/setup/alveo/u50_u50lv_u280#setup-alveo-accelerator-card-with-hbm-for-dpucahx8hl">Setup Alveo Accelerator Card with HBM for DPUCAHX8H/L</a> instructions. You will need to install the specified version of XRT on your host system (i.e. <em>not</em> in the Vitis-AI docker container), install the Alveo U50 card target platform also on your host system and then flash the Alveo U50 card. Note that a cold reboot will be necessary after flashing the Alveo U50.</p></li>
</ul>
<p>For more details, refer to the latest version of the <em>Vitis AI User Guide</em> (<a class="reference external" href="https://www.xilinx.com/html_docs/vitis_ai/1_3/zmw1606771874842.html">UG1414</a>).</p>
<p>This tutorial assumes the user is familiar with Python3, TensorFlow and has some knowledge of machine learning principles.</p>
</div>
<div class="section" id="setting-up-the-workspace-and-dataset">
<h1>Setting up the workspace and dataset<a class="headerlink" href="#setting-up-the-workspace-and-dataset" title="Permalink to this headline">¶</a></h1>
<ol>
<li><p>Copy the repository by doing either of the following:</p>
<ul class="simple">
<li><p>Download the repository as a ZIP file to the host machine, and then unzip the archive.</p></li>
<li><p>From a terminal, use the <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span></code> command.</p></li>
</ul>
</li>
<li><p>Download the Kaggle dogs-vs-cats dataset.</p>
<ul class="simple">
<li><p>Go to the <a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/data">Kaggle website</a> and register a new account if necessary.</p></li>
<li><p>Download the <a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/data">dataset</a>.</p></li>
<li><p>Move dogs-vs-cats.zip into the <code class="docutils literal notranslate"><span class="pre">files</span></code> folder in the design repository, which is the same folder that contains the python (<code class="docutils literal notranslate"><span class="pre">.py</span></code>) and shell (<code class="docutils literal notranslate"><span class="pre">.sh</span></code>) scripts.</p></li>
</ul>
<p>The Kaggle dog-vs-cats dataset consists of 25,000 images of varying dimensions, divided into two classes: cat and dog. Each image is intrinsically labelled or classified by its filename (for example, <code class="docutils literal notranslate"><span class="pre">cat.12.jpg</span></code>).</p>
<p>There is a set of unlabelled images which were part of the original Kaggle dogs-vs-cats challenge, but we will not use it in this tutorial. Only the 25000 images that are contained in the <code class="docutils literal notranslate"><span class="pre">train.zip</span></code> archive will be used.</p>
</li>
<li><p>Open a linux terminal, <code class="docutils literal notranslate"><span class="pre">cd</span></code> to the repository folder, and then <code class="docutils literal notranslate"><span class="pre">cd</span></code> to the <code class="docutils literal notranslate"><span class="pre">files</span></code> folder.</p></li>
<li><p>Start the Vitis AI GPU docker:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># navigate to densenet tutorial folder</span>
<span class="nb">cd</span> &lt;path_to_densenet_design&gt;/files

<span class="c1"># to start GPU docker container</span>
./docker_run.sh xilinx/vitis-ai-gpu:latest
</pre></div>
</div>
</li>
</ol>
<p>The docker container will start and after accepting the license agreement, you should see something like this in the terminal:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> ```shell
 ==========================================
 
 __      ___ _   _                   _____
 \ \    / (_) | (_)            /\   |_   _|
  \ \  / / _| |_ _ ___ ______ /  \    | |
   \ \/ / | | __| / __|______/ /\ \   | |
    \  /  | | |_| \__ \     / ____ \ _| |_
     \/   |_|\__|_|___/    /_/    \_\_____|
 
 ==========================================

 Docker Image Version:  1.3 
 Build Date: 2020-12-20
 VAI_ROOT: /opt/vitis_ai

 For TensorFlow Workflows do:
      conda activate vitis-ai-tensorflow 
 For Caffe Workflows do:
      conda activate vitis-ai-caffe 
 For Neptune Workflows do:
      conda activate vitis-ai-neptune 
 For PyTorch Workflows do:
      conda activate vitis-ai-pytorch 
 For TensorFlow 2.3 Workflows do:
      conda activate vitis-ai-tensorflow2 
 For Darknet Optimizer Workflows do:
      conda activate vitis-ai-optimizer_darknet 
 For Caffe Optimizer Workflows do:
      conda activate vitis-ai-optimizer_caffe 
 For TensorFlow 1.15 Workflows do:
      conda activate vitis-ai-optimizer_tensorflow 
 For LSTM Workflows do:
      conda activate vitis-ai-lstm 
 Vitis-AI /workspace &gt; 
 ```
</pre></div>
</div>
<blockquote>
<div><p>:bulb: <em>If you get a “Permission Denied” error when starting the docker container, it is almost certainly because the docker_run.sh script is not set to be executable. You can fix this by running the following command:</em></p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span> chmod +x docker_run.sh
</pre></div>
</div>
</div></blockquote>
<p>Activate the Tensorflow2 python virtual environment with <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">activate</span> <span class="pre">vitis-ai-tensorflow2</span></code> and you should see the prompt change to indicate that the environment is active:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>Vitis-AI /workspace &gt; conda activate vitis-ai-tensorflow2
<span class="o">(</span>vitis-ai-tensorflow2<span class="o">)</span> Vitis-AI /workspace &gt; 
</pre></div>
</div>
<p><em>The remainder of this README describes each single step to implement the tutorial, however a shell script called run_all.sh is provided which will run the complete flow:</em></p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>vitis-ai-tensorflow2<span class="o">)</span> Vitis-AI /workspace &gt; <span class="nb">source</span> run_all.sh
</pre></div>
</div>
</div>
<div class="section" id="step-0-converting-the-dataset-images-to-tfrecords">
<h1>Step 0 - Converting the dataset images to TFRecords<a class="headerlink" href="#step-0-converting-the-dataset-images-to-tfrecords" title="Permalink to this headline">¶</a></h1>
<p>To run step 0:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>vitis-ai-tensorflow2<span class="o">)</span> Vitis-AI /workspace &gt; python -u images_to_tfrec.py <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">|</span> tee tfrec.log
</pre></div>
</div>
<p>To speed up training, the JPEG images of the dogs-vs-cats dataset will be converted into the TFRecord format. The <code class="docutils literal notranslate"><span class="pre">images_to_tfrec.py</span></code> script will do the following:</p>
<ul class="simple">
<li><p>Unzip the dogs-vs-cats.zip archive into the folder set by the <code class="docutils literal notranslate"><span class="pre">--dataset_dir</span></code> argument.</p></li>
<li><p>Split the images into the train and test datasets, ensuring a balance between classes.</p></li>
<li><p>Convert each image and label into a TFRecord. The TFRecord files are written into .tfrecord files in the folder deefined by the <code class="docutils literal notranslate"><span class="pre">--tfrec_dir</span></code> argument.</p></li>
<li><p>Move the test images to a separate folder for later use on the target.</p></li>
</ul>
<p>Each TFRecord has five fields that are defined by the feature dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># features dictionary</span>
<span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;label&#39;</span> <span class="p">:</span> <span class="n">_int64_feature</span><span class="p">(</span><span class="n">label</span><span class="p">),</span>
  <span class="s1">&#39;height&#39;</span><span class="p">:</span> <span class="n">_int64_feature</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
  <span class="s1">&#39;width&#39;</span> <span class="p">:</span> <span class="n">_int64_feature</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
  <span class="s1">&#39;chans&#39;</span> <span class="p">:</span> <span class="n">_int64_feature</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span>
  <span class="s1">&#39;image&#39;</span> <span class="p">:</span> <span class="n">_bytes_feature</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The label is obtained by looking at the first part of the image file name and assigning either ‘0’ for dog or ‘1’ for cat:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">class_name</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="k">if</span> <span class="n">class_name</span> <span class="o">==</span> <span class="s1">&#39;dog&#39;</span><span class="p">:</span>
  <span class="n">label</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">label</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>Each JPEG image file is read into a TensorFlow string (tf.string) and its shape is obtained from the JPEG header - this avoids having to JPEG decode the image which means the script runs faster and also the TFRecord files are more compact:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># read the JPEG source file into a tf.string</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">filePath</span><span class="p">)</span>

<span class="c1"># get the shape of the image from the JPEG file header</span>
<span class="n">image_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">extract_jpeg_shape</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>The number of image/label pairs in each .tfrecord file is defined by the <code class="docutils literal notranslate"><span class="pre">--img_shard</span></code> argument.</p>
</div>
<div class="section" id="step-1-training">
<h1>Step 1 - Training<a class="headerlink" href="#step-1-training" title="Permalink to this headline">¶</a></h1>
<p>To run step 1:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>vitis-ai-tensorflow2<span class="o">)</span> Vitis-AI /workspace &gt; python -u train.py <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">|</span> tee train.log
</pre></div>
</div>
<blockquote>
<div><p>:bulb: <em>Training can take a considerable amount of time so a pretrained checkpoint is provided in the <code class="docutils literal notranslate"><span class="pre">pretrained</span></code> folder. To use this pretrained checkpoint, run the following commands instead of the command given above:</em></p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>mkdir -p float_model
cp -f pretrained/f_model.h5 float_model/.
</pre></div>
</div>
</div></blockquote>
<p>During training, the TFRecord files are read into the tf.data pipeline by the <code class="docutils literal notranslate"><span class="pre">input_fn_trn</span></code> function defined in <code class="docutils literal notranslate"><span class="pre">dataset_utils.py</span></code>. This function finds all TFRecord files whose names match the pattern train_*.tfrecord and creates a tf.data.Dataset object. The function also includes all the image pre-processing (resizing and random cropping, augmentation and normalization):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">input_fn_trn</span><span class="p">(</span><span class="n">tfrec_dir</span><span class="p">,</span><span class="n">batchsize</span><span class="p">,</span><span class="n">height</span><span class="p">,</span><span class="n">width</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Dataset creation and augmentation for training</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">tfrecord_files</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">list_files</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">/train_*.tfrecord&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tfrec_dir</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFRecordDataset</span><span class="p">(</span><span class="n">tfrecord_files</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">parser</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">resize_crop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">h</span><span class="o">=</span><span class="n">height</span><span class="p">,</span><span class="n">w</span><span class="o">=</span><span class="n">width</span><span class="p">),</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">augment</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">normalize</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">dataset</span>
</pre></div>
</div>
<p>The validation phase uses the <code class="docutils literal notranslate"><span class="pre">input_fn_test</span></code> function which will make a dataset from all TFRecord files which match the glob pattern test_*.tfrecord. Note how there is no augmentation, only resizing and normalization and the dataset does not repeat:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">input_fn_test</span><span class="p">(</span><span class="n">tfrec_dir</span><span class="p">,</span><span class="n">batchsize</span><span class="p">,</span><span class="n">height</span><span class="p">,</span><span class="n">width</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Dataset creation and augmentation for test</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">tfrecord_files</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">list_files</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">/test_*.tfrecord&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tfrec_dir</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFRecordDataset</span><span class="p">(</span><span class="n">tfrecord_files</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">parser</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">resize_crop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">h</span><span class="o">=</span><span class="n">height</span><span class="p">,</span><span class="n">w</span><span class="o">=</span><span class="n">width</span><span class="p">),</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">normalize</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataset</span>
</pre></div>
</div>
<p>The complete list of command line arguments of <code class="docutils literal notranslate"><span class="pre">train.py</span></code> are as follows:</p>
<p>|Argument|Default|Description|
|:——-|:—–:|:———-|
|–input_height|200|Input images are resized to input_height x input_width|
|–input_width|250|Input images are resized to input_height x input_width|
|–input_chan|3|Number of channels in input image - leave at default|
|–tfrec_dir|tfrecords|Folder containing TFRecord files|
|–batchsize|50|Batchsize used in training and validation - adjust for memory capacity of your GPU(s)|
|–epochs|250|Number of training epochs|
|–learnrate|0.001|Initial learning rate for optimizer|
|–chkpt_dir|float_model|Folder where trained checkpoint will be written|
|–tboard|tb_logs|Folder where TensorBoard logs will be written|</p>
</div>
<div class="section" id="step-2-quantization">
<h1>Step 2 - Quantization<a class="headerlink" href="#step-2-quantization" title="Permalink to this headline">¶</a></h1>
<p>To run step 2:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>vitis-ai-tensorflow2<span class="o">)</span> Vitis-AI /workspace &gt; python -u quantize.py --evaluate <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">|</span> tee quantize.log
</pre></div>
</div>
<p>The Xilinx DPU family of ML accelerators execute models and networks that have their parameters in integer format so we must convert the trained, floating-point checkpoint into a fixed-point integer checkpoint - this process is known as quantization.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">quantize.py</span></code> script will do the following:</p>
<ul class="simple">
<li><p>Make a folder (default name is quant_model) to contain the quantized model in HDF5 format.</p></li>
<li><p>Create a tf.data.Dataset object using the <code class="docutils literal notranslate"><span class="pre">input_fn_quant</span></code> defined in <code class="docutils literal notranslate"><span class="pre">dataset_utils.py</span></code></p>
<ul>
<li><p>this tf.data.Dataset is used to provide images for calibration.</p></li>
</ul>
</li>
<li><p>Run the quantization process using the Vitis-AI quantizer plug-in for TensorFlow2.</p></li>
<li><p>Save the quantized HDF5 model to the folder indicated by the <code class="docutils literal notranslate"><span class="pre">--quant_model</span></code> command line argument.</p></li>
<li><p>If the <code class="docutils literal notranslate"><span class="pre">--evaluate</span></code> command line argument is included, then the <code class="docutils literal notranslate"><span class="pre">quantize.py</span></code> script will evaluate the accuracy of the quantized model using the same test dataset that was used for validation during training.</p></li>
</ul>
</div>
<div class="section" id="step-3-compiling-for-the-target">
<h1>Step 3 - Compiling for the target<a class="headerlink" href="#step-3-compiling-for-the-target" title="Permalink to this headline">¶</a></h1>
<p>To run step 3, run the <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">compile.sh</span></code> with one of the target boards as a command line argument, for example:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>vitis-ai-tensorflow2<span class="o">)</span> Vitis-AI /workspace &gt; <span class="nb">source</span> compile.sh zcu102
</pre></div>
</div>
<p>The script also supports <code class="docutils literal notranslate"><span class="pre">u50</span></code> as a command line argument to target the Alveo U50. The <code class="docutils literal notranslate"><span class="pre">compile.sh</span></code> shell script will compile the quantized model and create an .xmodel file which contains the instructions and data to be executed by the DPU.</p>
</div>
<div class="section" id="step-4-running-the-application-on-the-target">
<h1>Step 4 - Running the application on the target<a class="headerlink" href="#step-4-running-the-application-on-the-target" title="Permalink to this headline">¶</a></h1>
<p>To prepare the images, xmodel and application code for copying to the selected target, run the following command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>vitis-ai-tensorflow2<span class="o">)</span> Vitis-AI /workspace &gt; python -u target.py <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">|</span> tee target.log
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">target.py</span></code> script will do the following:</p>
<ul class="simple">
<li><p>Resize the test images and copy them to the target folder.</p>
<ul>
<li><p>the number of images is set by the <code class="docutils literal notranslate"><span class="pre">--num_images</span></code> command line argument which defaults to 1000.</p></li>
</ul>
</li>
<li><p>Copy the compiled model to the target folder.</p></li>
<li><p>Copy the Python application code to the target folder.</p></li>
</ul>
<div class="section" id="zcu102">
<h2>ZCU102<a class="headerlink" href="#zcu102" title="Permalink to this headline">¶</a></h2>
<p>The entire <code class="docutils literal notranslate"><span class="pre">target</span></code> folder will be copied to the ZCU102. Copy it to the /home/root folder of the flashed SD card, this can be done in one of several ways:</p>
<ol class="simple">
<li><p>Direct copy to SD Card:</p></li>
</ol>
<ul class="simple">
<li><p>If the host machine has an SD card slot, insert the flashed SD card and when it is recognised you will see two volumes, BOOT and ROOTFS. Navigate into the ROOTFS and then into the /home folder.  Make the ./root folder writeable by issuing the command <code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">chmod</span> <span class="pre">-R</span> <span class="pre">777</span> <span class="pre">root</span></code> and then copy the entire <code class="docutils literal notranslate"><span class="pre">target</span></code> folder from the host machine into the /home/root folder of the SD card.</p></li>
<li><p>Unmount both the BOOT and ROOTFS volumes from the host machine and then eject the SD Card from the host machine.</p></li>
</ul>
<ol class="simple">
<li><p>With scp command:</p></li>
</ol>
<ul class="simple">
<li><p>If the target evaluation board is connected to the same network as the host machine, the <code class="docutils literal notranslate"><span class="pre">target</span></code> folder can be copied using scp.</p></li>
<li><p>The command will be something like <code class="docutils literal notranslate"><span class="pre">scp</span> <span class="pre">-r</span> <span class="pre">./build/target</span> <span class="pre">root&#64;192.168.1.227:~/.</span></code>  assuming that the target board IP address is 192.168.1.227 - adjust this as appropriate for your system.</p></li>
<li><p>If the password is asked for, insert ‘root’.</p></li>
</ul>
<p>With the <code class="docutils literal notranslate"><span class="pre">target</span></code> folder copied to the SD Card and the evaluation board booted, you can issue the command for launching the application - note that this done on the target evaluation board, not the host machine, so it requires a connection to the board such as a serial connection to the UART or an SSH connection via Ethernet.</p>
<p>The application can be started by navigating into the <code class="docutils literal notranslate"><span class="pre">target</span></code> folder on the evaluation board and then issuing the command <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">app_mt.py</span></code>. The application will start and after a few seconds will show the throughput in frames/sec, like this:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@xilinx-zcu102-2020_2:~/target# python3 app_mt.py 
------------------------------------
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">1</span>
 --model     :  customcnn.xmodel
------------------------------------
Pre-processing <span class="m">1000</span> images...
Starting <span class="m">1</span> threads...
------------------------------------
<span class="nv">Throughput</span><span class="o">=</span><span class="m">199</span>.88 fps, total <span class="nv">frames</span> <span class="o">=</span> <span class="m">1000</span>, <span class="nv">time</span><span class="o">=</span><span class="m">5</span>.0030 seconds
Post-processing <span class="m">1000</span> images..
Correct:975, Wrong:25, Accuracy:0.9750
------------------------------------
</pre></div>
</div>
<p>The throughput can be improved by increasing the number of threads with the <code class="docutils literal notranslate"><span class="pre">--threads</span></code> option:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@xilinx-zcu102-2020_2:~/target# python3 app_mt.py --threads <span class="m">6</span>
------------------------------------
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">6</span>
 --model     :  customcnn.xmodel
------------------------------------
Pre-processing <span class="m">1000</span> images...
Starting <span class="m">6</span> threads...
------------------------------------
<span class="nv">Throughput</span><span class="o">=</span><span class="m">760</span>.49 fps, total <span class="nv">frames</span> <span class="o">=</span> <span class="m">1000</span>, <span class="nv">time</span><span class="o">=</span><span class="m">1</span>.3149 seconds
Post-processing <span class="m">1000</span> images..
Correct:975, Wrong:25, Accuracy:0.9750
------------------------------------
</pre></div>
</div>
</div>
<div class="section" id="alveo-u50">
<h2>Alveo U50<a class="headerlink" href="#alveo-u50" title="Permalink to this headline">¶</a></h2>
<p>Note that these steps need to be run from inside of the Vitis-AI Docker container.</p>
<p>Run the <code class="docutils literal notranslate"><span class="pre">U50_overlay.sh</span></code> script (internet connection required) to download and install the correct overlay. Note that the U50 will need to have been flashed with the correct deployment shell - this should have been done in the <a class="reference external" href="#before-you-begin">Before You Begin</a> section above. The complete steps to run on the Alveo U50 are as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>Vitis-AI /workspace &gt; <span class="nb">source</span> U50_overlay.sh
Vitis-AI /workspace &gt; <span class="nb">cd</span> target
Vitis-AI /workspace &gt; /usr/bin/python3 app_mt.py --threads <span class="m">4</span>
</pre></div>
</div>
<p>As with the ZCU102, the performance can be increased by using more threads:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>------------------------------------
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">4</span>
 --model     :  customcnn.xmodel
------------------------------------
Pre-processing <span class="m">1000</span> images...
Starting <span class="m">4</span> threads...
------------------------------------
<span class="nv">Throughput</span><span class="o">=</span><span class="m">2706</span>.25 fps, total <span class="nv">frames</span> <span class="o">=</span> <span class="m">1000</span>, <span class="nv">time</span><span class="o">=</span><span class="m">0</span>.3695 seconds
Post-processing <span class="m">1000</span> images..
Correct:975, Wrong:25, Accuracy:0.9750
------------------------------------
</pre></div>
</div>
</hr>
<p class="sphinxhide" align="center"><sup>Copyright&copy; 2020-2021 Xilinx</sup></p></div>
</div>


           </div>
           
          </div>
          <footer>
<!-- Atalwar: Moved the footer code to layout.html to resolve conflict with the Xilinx template -->
</footer>

        </div>
      </div>


	  <!-- Sphinx Page Footer block -->
  

  <hr/>

  <div role="contentinfo" class="copyright">
    <p class="footerinfo">

    </p>
	<br>
  </div>
      </div>
    </section>


  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

   <script type="text/javascript">
    jQuery(function() { Search.loadIndex("searchindex.js"); });
  </script>

  <script type="text/javascript" id="searchindexloader"></script>


  
  
    
  



  <!--  Xilinx template footer block -->
							</div>
						</div>
					</div>
				</div>
				<div class="xilinxExperienceFragments experiencefragment aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
					<div class="xf-content-height">
						<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 ">
							<div class="footer parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
								<noindex>
                  <!-- make footer fixed - NileshP -->
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
                  <!-- make footer fixed NileshP-->
									<footer>
										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">
													<div class="row">
														<div class="footerSocial parbase">
															<div class="col-md-push-6 col-lg-push-6 col-md-6 col-lg-6">
																<ul class="list-inline pull-right social-menu">
																	<li>
																		<a href="https://www.linkedin.com/company/xilinx">
																		<span class="linkedin icon"></span>
																		<span class="sr-only">Connect on LinkedIn</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.twitter.com/XilinxInc">
																		<span class="twitter icon"></span>
																		<span class="sr-only">Follow us on Twitter</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.facebook.com/XilinxInc">
																		<span class="facebook icon"></span>
																		<span class="sr-only">Connect on Facebook</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.youtube.com/XilinxInc">
																		<span class="youtube icon"></span>
																		<span class="sr-only">Watch us on YouTube</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.xilinx.com/registration/subscriber-signup.html">
																		<span class="newsletter icon"></span>
																		<span class="sr-only">Subscribe to Newsletter</span>
																		</a>
																	</li>
																</ul>
															</div>
														</div>
														<div class="col-md-pull-6 col-lg-pull-6 col-md-6 col-lg-6">
															<span class="copyright">
                                  
                                  &copy; 2020–2021, Xilinx, Inc.
                              </span>
															<ul class="list-inline sub-menu">
																<li>
																	<a href="https://www.xilinx.com/about/privacy-policy.html">Privacy</a>
																</li>
																<li>
																	<a href="https://www.xilinx.com/about/legal.html">Legal</a>
																</li>
																<li>
																	<a href="https://www.xilinx.com/about/contact.html">Contact</a>
																</li>
															</ul>
														</div>
													</div>
												</div>
											</div>
										</div>
									</footer>
								</noindex>
							</div>
						</div>
					</div>
				</div>
				<div class="quicklinks parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
					<noindex>
						<span class="quickLinks">
							<ul>
								<li>
									<a href="#top" class="btn backToTop">
									<span class="fas fa-angle-up" aria-hidden="true"></span>
									</a>
								</li>
							</ul>
						</span>
					</noindex>
				</div>
			</div>
		</div>
		<script>window.CQ = window.CQ || {}</script>
		<script src="https://static.cloud.coveo.com/searchui/v2.4382/js/CoveoJsSearch.Lazy.min.js"></script>
		<script>
			var underscoreSetup = function () {
			  _.templateSettings.interpolate = /\{\{=([^-][\S\s]+?)\}\}/g;
			  _.templateSettings.evaluate = /\{\{([^-=][\S\s]+?)\}\}/g;
			  _.templateSettings.escape = /\{\{-([^=][\S\s]+?)\}\}/g;
			}

			underscoreSetup();
		</script>
	</body>
</html>