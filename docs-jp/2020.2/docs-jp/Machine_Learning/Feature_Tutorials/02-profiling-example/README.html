


<!DOCTYPE HTML>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
	<head>
		<meta charset="utf-8">
		
		<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>
		<link rel="stylesheet" href="https://static.cloud.coveo.com/searchui/v2.4382/css/CoveoFullSearch.css"/>
		<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
		<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
		<meta name="description"/>
		<meta name="keywords"/>
		<meta property="og:title" content=""/>
		<meta property="og:description"/>
		<!-- favicon -->
		<link rel="icon" type="image/vnd.microsoft.icon" href="../../../_static/favicon.ico"/>
		<link rel="shortcut icon" type="image/vnd.microsoft.icon" href="../../../_static/favicon.ico"/>
		<!-- Fonts -->
		<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet" type="text/css"/>

  
  
  
  

  
      <script type="text/javascript" src="../../../_static/js/jquery.min.js"></script>
	  <script type="text/javascript" src="../../../_static/js/gtm.js"></script>
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/d3dd8c60ed.js"></script>
    <script type="text/javascript" src="../../../_static/js/common-ui-all.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/header-footer.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/jquery-ui.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/CoveoJsSearch.Lazy.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/linkid.js"></script>
    <script type="text/javascript" src="../../../_static/js/Searchbox.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/common-ui-all.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/header-footer.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/pro.min.css" media="all" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
	</head>
	<body>
		<div class="xilinx-bs3"/>
		<div class="root responsivegrid">
			<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 aem-Grid--large--16 aem-Grid--xlarge--16 aem-Grid--xxlarge--16 aem-Grid--xxxlarge--16 ">
				<div class="xilinxExperienceFragments experiencefragment aem-GridColumn aem-GridColumn--default--12">
					<div class="xf-content-height">
						<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 ">
							<div class="header parbase aem-GridColumn aem-GridColumn--default--12">
								<noindex>
									<header data-component="header">
										<nav class="navbar navbar-default aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid main-nav">
													<div class="row">
														<div class="col-xs-12">
															<div class="logo-column">
																<div class="logo">
																	<a href="https://www.xilinx.com/">
																	<img src="https://www.xilinx.com/etc.clientlibs/site/clientlibs/xilinx/all/resources/imgs/header/xilinx-header-logo.svg" title="Xilinx Inc"/>
																	</a>
																</div>
															</div>
															<div class="navbar-column">
																<div class="navbar navbar-collapse collapse" id="xilinx-main-menu">
																	<div class="mobile-search-container">
																		<div id="headerSearchBox" class="headerSearch"
																			data-component="header-search"
																			data-redirect-if-empty="false"
																			data-coveo-access-token="xxa237d4dd-f0aa-47fc-9baa-af9121851b33"
																			data-coveo-organization-id="xilinxcomprode2rjoqok">
																			<div class='coveo-search-section'>
																				<div class="CoveoAnalytics" data-search-hub="Site"></div>
																				<ul class="dropdown-menu options">
																					<li class="option" data-label="All" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-search-hub="Site">
																						<a href="#">
																						All</a>
																					</li>
																					<li data-label="Silicon Devices" data-action-link="https://www.xilinx.com//products/silicon-devices/si-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Silicon Devices</a>
																					</li>
																					<li data-label="Boards and Kits" data-action-link="https://www.xilinx.com//products/boards-and-kits/bk-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Boards and Kits</a>
																					</li>
																					<li data-label="Intellectual Property" data-action-link="https://www.xilinx.com//products/intellectual-property/ip-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Intellectual Property</a>
																					</li>
																					<li data-label="Support" class="option" data-action-link="https://www.xilinx.com/search/support-keyword-search.html" data-search-hub="Support">
																						<a href="#">
																						Support</a>
																						<ul>
																							<li data-label="Documentation" data-action-link="https://www.xilinx.com//support/documentation-navigation/documentation-keyword-search.html" data-search-hub="Document">
																								<a href="#">
																								Documentation</a>
																							</li>
																							<li data-label="Knowledge Base" data-action-link="https://www.xilinx.com//support/answer-navigation/answer-keyword-search.html" data-search-hub="AnswerRecord">
																								<a href="#">
																								Knowledge Base</a>
																							</li>
																							<li data-label="Community Forums" data-action-link="https://www.xilinx.com/search/forums-keyword-search.html" data-search-hub="Forums">
																								<a href="#">
																								Community Forums</a>
																							</li>
																						</ul>
																					</li>
																					<li data-label="Partners" data-action-link="https://www.xilinx.com//alliance/member-keyword-search.html" data-search-hub="Partner">
																						<a href="#">
																						Partners</a>
																					</li>
																					<li data-label="Videos" data-action-link="https://www.xilinx.com/video/video-keyword-search.html" data-search-hub="Video">
																						<a href="#">
																						Videos</a>
																					</li>
																					<li data-label="Press" data-action-link="https://www.xilinx.com/search/press-keyword-search.html" data-search-hub="Press">
																						<a href="#">
																						Press</a>
																					</li>
																				</ul>
																				<a href="#" class="btn dropdown-toggle value" data-toggle="dropdown"></a>
																				<div class="CoveoSearchbox" data-id="coveosearchbox" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-placeholder="Search Xilinx"></div>
																			</div>
																		</div>
																	</div>
																	<ul class="nav navbar-nav nav-justified">
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/applications.html">
																			Applications</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/products/silicon-devices.html">
																			Products</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://developer.xilinx.com/">
																			Developers</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/support.html">
																			Support</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/about/company-overview.html">
																			About</a>
																		</li>
																	</ul>
																</div>
															</div>
															<script type="text/javascript" src="../../../_static/js/gtm.js"></script>
															<!--<div class="mini-nav">
																<button type="button" data-function="xilinx-mobile-menu" id="nav-toggle" class="navbar-toggle collapsed visible-xs-block" aria-expanded="false">
																<span></span>
																<span></span>
																<span></span>
																<span></span>
																</button>
																<ul class="list-inline">
																	<li class="dropdown user-menu">
																		<button data-toggle="dropdown">
																		<span class="sr-only">Account</span>
																		<span class="fas fa-user"></span>
																		</button>
																		<ul class="dropdown-menu">
																			<li>
																				<a href="https://www.xilinx.com/myprofile/subscriptions.html">
																				My Account</a>
																			</li>
																			<li>
																				<a href="https://www.xilinx.com/registration/create-account.html">
																				Create Account</a>
																			</li>
																			<li>
																				<a href="https://www.xilinx.com/bin/protected/en/signout">
																				Sign Out</a>
																			</li>
																		</ul>
																	</li>
																	<li class="hidden-xs">
																		<button data-function="search-toggle">
																		<span class="sr-only">Search</span>
																		<span class="far fa-search"></span>
																		</button>
																	</li>
																</ul>
															</div>
															-->
															<div class="search-container">
																<div id="headerSearchBox" class="headerSearch"
																	data-component="header-search"
																	data-redirect-if-empty="false"
																	data-coveo-access-token="xxa237d4dd-f0aa-47fc-9baa-af9121851b33"
																	data-coveo-organization-id="xilinxcomprode2rjoqok">
																	<div class='coveo-search-section'>
																		<div class="CoveoAnalytics" data-search-hub="Site"></div>
																		<ul class="dropdown-menu options">
																			<li class="option" data-label="All" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-search-hub="Site">
																				<a href="#">
																				All</a>
																			</li>
																			<li data-label="Silicon Devices" data-action-link="https://www.xilinx.com/products/silicon-devices/si-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Silicon Devices</a>
																			</li>
																			<li data-label="Boards and Kits" data-action-link="https://www.xilinx.com/products/boards-and-kits/bk-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Boards and Kits</a>
																			</li>
																			<li data-label="Intellectual Property" data-action-link="https://www.xilinx.com/products/intellectual-property/ip-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Intellectual Property</a>
																			</li>
																			<li data-label="Support" class="option" data-action-link="https://www.xilinx.com/search/support-keyword-search.html" data-search-hub="Support">
																				<a href="#">
																				Support</a>
																				<ul>
																					<li data-label="Documentation" data-action-link="https://www.xilinx.com/support/documentation-navigation/documentation-keyword-search.html" data-search-hub="Document">
																						<a href="#">
																						Documentation</a>
																					</li>
																					<li data-label="Knowledge Base" data-action-link="https://www.xilinx.com/support/answer-navigation/answer-keyword-search.html" data-search-hub="AnswerRecord">
																						<a href="#">
																						Knowledge Base</a>
																					</li>
																					<li data-label="Community Forums" data-action-link="https://www.xilinx.com/search/forums-keyword-search.html" data-search-hub="Forums">
																						<a href="#">
																						Community Forums</a>
																					</li>
																				</ul>
																			</li>
																			<li data-label="Partners" data-action-link="https://www.xilinx.com/alliance/member-keyword-search.html" data-search-hub="Partner">
																				<a href="#">
																				Partners</a>
																			</li>
																			<li data-label="Videos" data-action-link="https://www.xilinx.com/video/video-keyword-search.html" data-search-hub="Video">
																				<a href="#">
																				Videos</a>
																			</li>
																			<li data-label="Press" data-action-link="https://www.xilinx.com/search/press-keyword-search.html" data-search-hub="Press">
																				<a href="#">
																				Press</a>
																			</li>
																		</ul>
																		<a href="#" class="btn dropdown-toggle value" data-toggle="dropdown"></a>
																		<div class="CoveoSearchbox" data-id="coveosearchbox" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-placeholder="Search Xilinx"></div>
																	</div>
																</div>
																<button data-function="search-toggle">
																<span class="sr-only">Search</span>
																<span class="far fa-times"></span>
																</button>
															</div>
														</div>
													</div>
												</div>
											</div>
										</nav>
									</header>
								</noindex>
							</div>
						</div>
					</div>
				</div>
				<div class="parsys aem-GridColumn--xxxlarge--none aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
						<div class="container-fluid">
							<div class="row">
							<div class="col-xs-12">
   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> Vitis チュートリアル
          

          
          </a>

          
            
            
              <div class="version">
                2020.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

      
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
            
            
            
              
            
            
              <p class="caption"><span class="caption-text">English version</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/master/docs/index.html">Master</a></li>
</ul>
<p class="caption"><span class="caption-text">入門</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis/README.html">Vitis フロー 101 チュートリアル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis_HLS/README.html">Vitis HLS の解析および最適化</a></li>
</ul>
<p class="caption"><span class="caption-text">機械学習 (英語版)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Introduction to Machine Learning with Vitis AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../README.html#design-tutorials">Design Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../README.html#feature-tutorials">Feature Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">アクセラレーション</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html">Vitis ハードウェア アクセラレータの概要</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html#id1">設計チュートリアル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html#id2">機能チュートリアル</a></li>
</ul>
<p class="caption"><span class="caption-text">AI エンジン開発 (英語版)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../AI_Engine_Development/README.html">Design Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../AI_Engine_Development/README.html#feature-tutorials">Feature Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">プラットフォーム作成チュートリアル</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/README.html">プラットフォームの作成</a></li>
</ul>
<p class="caption"><span class="caption-text">XRT および Vitis システム最適化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/README.html">設計チュートリアル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/README.html#id2">機能チュートリアル</a></li>
</ul>
<p class="caption"><span class="caption-text">バージョン</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/2020-1/docs/README.html">2020.1</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Xilinx/Vitis-Tutorials/blob/Vitis-Tutorials-2019.2-Hotfix1/README.md">2019.2</a></li>
</ul>

            
			
			<p class="caption"><span class="caption-text">This Page</span></p>
				<ul class="current">
				  <li class="toctree-l1"><a href="../../../_sources/Machine_Learning/Feature_Tutorials/02-profiling-example/README.md.txt"
						rel="nofollow">Show Source</a></li>
				</ul>
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Vitis チュートリアル</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Current Status</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/Machine_Learning/Feature_Tutorials/02-profiling-example/README.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <table>
 <tr>
   <td align="center"><img src="https://www.xilinx.com/content/dam/xilinx/imgs/press/media-kits/corporate/xilinx-logo.png" width="30%"/><h1>Vitis AI Tutorials</h1>
   </td>
 </tr>
 <tr>
 <td align="center"><h3> Profiling a CNN Using DNNDK or VART with Vitis AI</h3>
 </td>
 </tr>
</table><div class="section" id="current-status">
<h1>Current Status<a class="headerlink" href="#current-status" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Tested with Vitis AI 1.3.</p></li>
<li><p>Tested in hardware on ZCU102</p></li>
</ul>
<p>###Date: 14 Jan 2021</p>
</div>
<div class="section" id="introduction">
<h1>1 Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>This tutorial shows you different ways to profile a CNN application running on the ZCU102 target board with Vitis™ AI 1.3, which is a set of optimized IP, tools, libraries, models and example designs valid for AI inference on both Xilinx edge devices and Alveo™ Data Center accelerator cards.</p>
<p>For more information, see the following sites:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://developer.xilinx.com/en/get-started/ai.html">Vitis AI product page</a></p></li>
<li><p><a class="reference external" href="https://www.xilinx.com/products/design-tools/ai-inference/edge-ai-platform.html">AI Edge Platform product page</a></p></li>
<li><p><a class="reference external" href="https://www.xilinx.com/products/boards-and-kits/alveo.html">Alveo Data Center Accelerator Card product page</a></p></li>
</ul>
<p>In order to follow this tutorial, you must have already trained and quantized your CNN, whether you selected Caffe or TensorFlow.
In fact compiling, running and debugging the C++ (or Python) application on the embedded system composed by the Deep Processor Unit (DPU)
and the ARM CPU is almost independent from the adopted ML framework.</p>
<p>Note that the previous release of this tutorial -based on Vitis AI 1.2- is available <a class="reference external" href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/Profiling-DNNDK-Examples">here</a>.</p>
</div>
<div class="section" id="prerequisites">
<h1>2 Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Ubuntu 16.04 host PC with Python 3.6.</p></li>
<li><p>The entire repository of <a class="reference external" href="https://github.com/Xilinx/Vitis-AI">Vitis AI stack release 1.3</a> from <a class="reference external" href="https://www.github.com/Xilinx">www.github.com/Xilinx</a>.</p></li>
<li><p>Accurate reading of <a class="reference external" href="https://www.xilinx.com/support/documentation/sw_manuals/vitis_ai/1_3/ug1414-vitis-ai.pdf">Vitis AI User Guide UG1414 v1.3</a>. In particular:</p></li>
</ul>
<ol class="simple">
<li><p>“Vitis AI Overview” in Chapter 1 with DPU naming and guidelines to download the tools container available from <a class="reference external" href="https://hub.docker.com/r/xilinx/vitis-ai/tags">docker hub</a> and the Runtime Package for edge (MPSoC) devices.</p></li>
<li><p>“Installation and Setup” instructions of Chapter 2 for both host and target;</p></li>
<li><p>“Quantizing the Model” in Chapter 4 and “Compiling the Model” in Chapter 5.</p></li>
<li><p>“Programming with VART” APIs in Chapter 6.</p></li>
</ol>
<ul class="simple">
<li><p>The <a class="reference external" href="https://www.xilinx.com/products/boards-and-kits/ek-u1-zcu102-g.html">ZCU102</a> evaluation board with its <a class="reference external" href="https://www.xilinx.com/bin/public/openDownload?filename=xilinx-zcu102-dpu-v2020.2-v1.3.0.img.gz">image file</a>, which contains a pre-built working design for the ZCU102 with the DPUCZDX8G (renamed shortly as “DPUv2” in the following).</p></li>
<li><p>In this tutorial you will use FCN8 and AlexNet CNNs and their <code class="docutils literal notranslate"><span class="pre">elf</span></code> files that were respectively generated in the Vitis AI 1.2 Tutorials:</p>
<ul>
<li><p><a class="reference external" href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/VAI-KERAS-FCN8-SEMSEG">FCN8 and UNET Semantic Segmentation with Keras and Xilinx Vitis AI</a></p></li>
<li><p><a class="reference external" href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/VAI-Caffe-ML-CATSvsDOGS">Quantization and Pruning of AlexNet CNN trained in Caffe with Cats-vs-Dogs dataset</a></p></li>
</ul>
</li>
<li><p>Familiarity with Deep Learning principles.</p></li>
</ul>
<div class="section" id="dos-to-unix-conversion">
<h2>2.1 Dos-to-Unix Conversion<a class="headerlink" href="#dos-to-unix-conversion" title="Permalink to this headline">¶</a></h2>
<p>In case you might get some strange errors during the execution of the scripts, you have to pre-process -just once- all the<code class="docutils literal notranslate"><span class="pre">*.sh</span></code> shell and the python <code class="docutils literal notranslate"><span class="pre">*.py</span></code> scripts with the <a class="reference external" href="http://archive.ubuntu.com/ubuntu/pool/universe/d/dos2unix/dos2unix_6.0.4.orig.tar.gz">dos2unix</a> utility.
In that case run the following commands from your Ubuntu host PC (out of the Vitis AI docker images):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo apt-get install dos2unix
<span class="nb">cd</span> &lt;WRK_DIR&gt; <span class="c1">#your working directory</span>
<span class="k">for</span> file in <span class="k">$(</span>find . -name <span class="s2">&quot;*.sh&quot;</span><span class="k">)</span><span class="p">;</span> <span class="k">do</span>
dos2unix <span class="si">${</span><span class="nv">file</span><span class="si">}</span>
<span class="k">done</span>
</pre></div>
</div>
</div>
<div class="section" id="working-directory">
<h2>2.2 Working Directory<a class="headerlink" href="#working-directory" title="Permalink to this headline">¶</a></h2>
<p>In the following of this document, it is assumed that you have cloned the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI">Vitis AI stack release 1.3</a> and this is your working directory <code class="docutils literal notranslate"><span class="pre">&lt;WRK_DIR&gt;</span></code> (for example in my case I renamed it shortly as <code class="docutils literal notranslate"><span class="pre">~/ML/VAI1v3</span></code>).</p>
<p>This tutorial repository is then cloned and placed in a <code class="docutils literal notranslate"><span class="pre">tutorial</span></code> sub-folder below the <code class="docutils literal notranslate"><span class="pre">&lt;WRK_DIR</span></code> directory and then renamed as <code class="docutils literal notranslate"><span class="pre">VAI-Profiling-DNNDK-VART</span></code>.</p>
</div>
<div class="section" id="before-starting-with-vitis-ai-1-3">
<h2>2.3 Before starting with Vitis AI 1.3<a class="headerlink" href="#before-starting-with-vitis-ai-1-3" title="Permalink to this headline">¶</a></h2>
<p>To list the currently available docker images run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker images <span class="c1"># to list the current docker images available in the host pc</span>
</pre></div>
</div>
<p>and you should see something like in the following text:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>REPOSITORY            TAG                               IMAGE ID            CREATED             SIZE
xilinx/vitis-ai-gpu   latest                            1bc243fc037a        41 minutes ago      19GB
</pre></div>
</div>
<p>To launch the docker container with Vitis AI tools - to do all the steps from CNN training to generation of the ELF file for the DPU - based on CPU (or GPU), execute the following commands from the <code class="docutils literal notranslate"><span class="pre">&lt;WRK_DIR&gt;</span></code> folder:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> &lt;WRK_DIR&gt; <span class="c1"># you are now in Vitis_AI subfolder</span>
./docker_run.sh xilinx/vitis-ai-gpu:1.3

<span class="c1">#if you want to use tensorflow</span>
conda activate vitis-ai-tensorflow

<span class="c1">#if you want to use caffe</span>
conda activate vitis-ai-caffe
</pre></div>
</div>
<p>Note that the container maps the shared folder <code class="docutils literal notranslate"><span class="pre">/workspace</span></code> with the file system of the Host PC from where you launch the above command, which is <code class="docutils literal notranslate"><span class="pre">&lt;WRK_DIR&gt;</span></code> in your case.
This shared folder enables you to transfer files from the Host PC to the docker container and vice versa.</p>
<p>The docker container does not have any graphic editor, so it is recommended that you work with two terminals and you point to the same folder, in one terminal you use the docker container commands and in the other terminal you open any graphic editor you like.</p>
<p>Note that docker does not have an automatic garbage collection system as of now. You can use this command to do a manual garbage collection:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>docker rmi -f $(docker images -f &quot;dangling=true&quot; -q)
</pre></div>
</div>
</div>
<div class="section" id="dnndk-setup">
<h2>2.4 DNNDK Setup<a class="headerlink" href="#dnndk-setup" title="Permalink to this headline">¶</a></h2>
<p>Before you start the tutorial, you have to follow and execute the Step1 and Step2 instructions of the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/blob/master/demo/DNNDK/README">DNNDK</a> section to setup <code class="docutils literal notranslate"><span class="pre">petalinux_sdk</span></code> and the ZCU102 SD card image.</p>
<p><strong>Important</strong>: In GitHub you cannot store a file larger than 25MB, so all the <code class="docutils literal notranslate"><span class="pre">.elf</span></code> and <code class="docutils literal notranslate"><span class="pre">.so</span></code> files were compressed with <code class="docutils literal notranslate"><span class="pre">gzip</span></code>. Before running any script, you must manually uncompress those files.</p>
</div>
</div>
<div class="section" id="q-a-about-profiling-and-multithreading">
<h1>3.0 Q&amp;A about Profiling and Multithreading<a class="headerlink" href="#q-a-about-profiling-and-multithreading" title="Permalink to this headline">¶</a></h1>
<details><summary>Does the multithreading execution of kernels running in parallel deliver deterministic results?</summary>
</p>
  The latency through the DPU (assuming it has data available and the system is not memory bound) should be somewhat deterministic. The latency from when you start a thread to the time when it completes is not necessarily deterministic as it may depend on the number of threads launched, system utilization, and other settings. There is also the capability with the DNNDK APIs to set ``core affinity`` (which DPU will execute which task) as well as ``priority`` (which task takes priority), so if you have a higher priority task, you can set the priority higher for that task.</details>
</p>
<details><summary>Is there any other way to find out the optimum number of threads or only testing?</summary>
</p>
 It seems that most of the time, for the 3 B4096 DPUs on the ZCU102 board, 6 threads is a good number.  That said, it depends on the number of DPUs available, the time it takes to execute the model, and the software loading of the system.  Once you have the multithreaded application setup, it should be pretty easy to vary this number at runtime.</details>
</p>
<details><summary>What does one "kernel" mean?</summary>
</p>
  A kernel is the instantiation of a task (for example a certain CNN) on the DPU.</details>
</p>
<details><summary>How do the kernels communicate to each other, or do they run completely independent to each other?</summary>
</p>
  The kernels are totally independent from each other.</details>
</p>
<details><summary>How are the overall processing steps divided up in kernels?</summary>
</p>
  The kernel or DPU task (or "runner") is the CNN model.  When you compile the model it becomes a kernel, so the processing steps are those contained within the model.</details>
</p>
<details><summary>Does one frame map to one kernel, or is one frame processed by multiple kernels?</summary>
</p>
  One frame maps to one kernel, though perhaps it is possible that you could have multiple inputs to a CNN model and you could possibly be inputting multiple frames or other data to the various inputs. It is also possible that you could segment a model into multiple kernels, though you would need to compile each one individually, then take the output from that kernel and feed it to the next. You could theoretically create a pipeline in this case that uses multiple DPUs, each which execute a portion of the model and are fed by the output of the previous kernel.</details>
</p>
<details><summary>Is there any method to define what is being processed within one kernel?</summary>
</p>
  You have the ability to define what is in the CNN model. If you want to only process a portion of the model, then make that the output layer or input layer when you quantize it with ``vai_q_*`` and compile it with ``vai_c_*`` (where ``*`` means either ``caffe`` or ``tensorflow``).</details>
</p>
<details><summary>What can I do with the profiling results?</summary>
</p>
  Once the fine-grained profiling is done over one specific CNN model, the Vitis AI compiler (``vai_c_*``) does not currently offer open parameters/options for the CNN performance tuning in the ``elf`` file. However, if you are not satisfied with the performance delivered by the DPU core, you can try to modify the DPU configurations in order to obtain better performance. For example, you can try applying more advanced DPU architectures from B1152 to B4096, or applying ``high RAM usage``.  Refer to [Configurate the DPU](https://github.com/Xilinx/Vitis-AI/blob/v1.2.1/DPU-TRD/prj/Vivado/README.md) for more details. Otherwise, if the DPU core offers enough performance, you can try to modify the DPU configurations with lower logic resources, which will be beneficial for other subsystems to be implemented later in the FPGA.</details></div>
<div class="section" id="dpu-profiling-with-dnndk-c-apis">
<h1>4 DPU Profiling with DNNDK C++ APIs<a class="headerlink" href="#dpu-profiling-with-dnndk-c-apis" title="Permalink to this headline">¶</a></h1>
<p>There are at least three possible <strong>profiling methods</strong> to measure the throughput performance of the embedded system composed by the ARM CPU and the DPU IP core:</p>
<ul class="simple">
<li><p>manually profiling only the CNN APIs called by the ARM CPU,</p></li>
<li><p>automatically profiling all the CNN layers running on the DPU IP core (which is called <strong>fine-grained profiling</strong>),</p></li>
<li><p>manually computing the elapsed time - with image pre-processing and data loading operation included</p></li>
</ul>
<p>The first and third profiling methods require a different compilation flag from the second method: <code class="docutils literal notranslate"><span class="pre">--options</span>&#160;&#160;&#160; <span class="pre">&quot;{'mode':'normal'}&quot;</span></code> (for methods 1 and 3) and  <code class="docutils literal notranslate"><span class="pre">--options</span>&#160;&#160;&#160; <span class="pre">&quot;{'mode':'debug'}&quot;</span></code> (for method 2) in the <code class="docutils literal notranslate"><span class="pre">vai_c</span></code> script used to generate the DPU <code class="docutils literal notranslate"><span class="pre">elf</span></code> file from the quantized CNN. This is illustrated in the following fragments of code, respectively for a CNN quantized with <code class="docutils literal notranslate"><span class="pre">vitis-ai-caffe</span></code> or <code class="docutils literal notranslate"><span class="pre">vitis-ai-tensorflow</span></code> anaconda environments:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># conda activate vai_caffe</span>
vai_c_caffe  --prototxt<span class="o">=</span><span class="si">${</span><span class="nv">model_dir</span><span class="si">}</span>/deploy.prototxt     <span class="se">\</span>
     --caffemodel<span class="o">=</span><span class="si">${</span><span class="nv">model_dir</span><span class="si">}</span>/deploy.caffemodel <span class="se">\</span>
     --output_dir<span class="o">=</span><span class="si">${</span><span class="nv">output_dir</span><span class="si">}</span>                  <span class="se">\</span>
     --net_name<span class="o">=</span><span class="si">${</span><span class="nv">CNN</span><span class="si">}</span>                           <span class="se">\</span>
     --arch /opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU102/arch.json <span class="se">\</span>
     --options    <span class="s2">&quot;{&#39;mode&#39;:&#39;normal&#39;, &#39;save_kernel&#39;:&#39;&#39;}&quot;</span>
<span class="c1">#    --options    &quot;{&#39;mode&#39;:&#39;debug&#39;}&quot;</span>

<span class="c1"># conda activate vai_tensorflow</span>
vai_c_tensorflow <span class="se">\</span>
       --frozen_pb<span class="o">=</span><span class="si">${</span><span class="nv">model_dir</span><span class="si">}</span>/deploy_model.pb <span class="se">\</span>
       --output_dir<span class="o">=</span><span class="si">${</span><span class="nv">output_dir</span><span class="si">}</span>               <span class="se">\</span>
       --net_name<span class="o">=</span><span class="si">${</span><span class="nv">CNN</span><span class="si">}</span>                        <span class="se">\</span>
       --arch /opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU102/arch.json <span class="se">\</span>
       --options    <span class="s2">&quot;{&#39;mode&#39;:&#39;normal&#39;}&quot;</span>
<span class="c1">#      --options    &quot;{&#39;mode&#39;:&#39;debug&#39;}&quot;       </span>
</pre></div>
</div>
<p>In both the first and second methods, the image preprocessing CPU overhead is not taken in account. In fact, in the current application, the ARM CPU runs the preprocessing in software, which is surely not an efficient solution being it very slow. In real life scenario an hardware accelerator would do that in the MPSoC fabric with much smaller latency, typically using
the <a class="reference external" href="https://github.com/Xilinx/Vitis_Libraries/tree/master/vision">Vitis Vision library</a> based on Open-CV functions optimized for the FPGA.</p>
<p>While the results measured by method 1 and 2 should be quite in agreement (note that method 2 is the most precise), the results of method 3 should be worst because of the overhead of the ARM CPU (running in software the tasks of file I/O operations). Note also that all those results must be measured with a single thread execution.</p>
<div class="section" id="profiling-alexnet-cnn-for-image-classification">
<h2>4.1 Profiling AlexNet CNN for Image Classification<a class="headerlink" href="#profiling-alexnet-cnn-for-image-classification" title="Permalink to this headline">¶</a></h2>
<p>In the following of this Section you will see how profiling the <code class="docutils literal notranslate"><span class="pre">AlexNet</span></code> CNN trained with Caffe on the <code class="docutils literal notranslate"><span class="pre">Dogs</span> <span class="pre">vs.</span> <span class="pre">Cats</span></code> dataset for image classification with RGB images of size 227x227x3, as illustrated in the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/VAI-Caffe-ML-CATSvsDOGS">UG1336</a>.The same concepts are valid also for any other CNN.</p>
<p>To save time, you can run profiling using one input image, as its results do not depend on the amount of input images. Due to that the folder <code class="docutils literal notranslate"><span class="pre">test_image</span></code> contains only one image, differently from the archive <code class="docutils literal notranslate"><span class="pre">test_images.tar.gz</span></code>.</p>
<p>Make an archive of the <code class="docutils literal notranslate"><span class="pre">alexnet_zcu102</span></code> folder and then copy <code class="docutils literal notranslate"><span class="pre">alexnet_zcu102.tar</span></code> to your ZCU102 target board with <code class="docutils literal notranslate"><span class="pre">scp</span></code> utility: for example, assuming your target board have static IP address value of <code class="docutils literal notranslate"><span class="pre">192.168.1.40</span></code>, the command will be <code class="docutils literal notranslate"><span class="pre">scp</span> <span class="pre">./alexnet_zcu102.tar</span> <span class="pre">root&#64;192.168.1.40:~/</span></code> (password is <code class="docutils literal notranslate"><span class="pre">root</span></code>).</p>
<p>All the results of next subsections are obtained by running the following commands (they are all contained in the script <code class="docutils literal notranslate"><span class="pre">run_all.sh</span></code>) directly from the ZCU102 board:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># extract the archive</span>
<span class="nb">cd</span> ~
mv alexnet_zcu102.tar ~/DNNDK/
<span class="nb">cd</span> ~/DNNDK
tar -xvf alexnet_zcu102.tar
<span class="nb">cd</span> alexnet_zcu102
<span class="c1"># crosscompile the C++ applications with DNNDK APIs  </span>
bash ./crosscompile_alexnet.sh
<span class="c1"># extract the test input images</span>
tar -xvf test_images.tar
<span class="c1"># run baseline CNN</span>
<span class="nb">cd</span> baseline
bash ./run_all_baseline.sh
<span class="c1"># run pruned CNN</span>
<span class="nb">cd</span> ../pruned
bash ./run_all_pruned.sh  
</pre></div>
</div>
<p>Log files were captured for your comfort and placed in the <code class="docutils literal notranslate"><span class="pre">alexnet_zcu102/log/</span></code> folder as a reference of what you should see during the processing.</p>
<div class="section" id="first-method">
<h3>4.1.1 First Method<a class="headerlink" href="#first-method" title="Permalink to this headline">¶</a></h3>
<p>In the first profiling method the DPU elapsed time is measured “manually” with the following fragment of C++ code in the <code class="docutils literal notranslate"><span class="pre">run_CNN()</span></code> subroutine from <a class="reference external" href="files/alexnet_zcu102/baseline/src/fps_main_method1.cc">fps_main_method1.cc</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#define SHOWTIME</span>

<span class="c1">#ifdef SHOWTIME</span>
<span class="c1">#define _T(func)                                                              \</span>
        <span class="n">auto</span> <span class="n">_start</span> <span class="o">=</span> <span class="n">system_clock</span><span class="p">::</span><span class="n">now</span><span class="p">();</span>                                    \
        <span class="n">func</span><span class="p">;</span>                                                                 \
        <span class="n">auto</span> <span class="n">_end</span> <span class="o">=</span> <span class="n">system_clock</span><span class="p">::</span><span class="n">now</span><span class="p">();</span>                                      \
        <span class="n">auto</span> <span class="n">duration</span> <span class="o">=</span> <span class="p">(</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">microseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">_end</span> <span class="o">-</span> <span class="n">_start</span><span class="p">))</span><span class="o">.</span><span class="n">count</span><span class="p">();</span> \
        <span class="n">string</span> <span class="n">tmp</span> <span class="o">=</span> <span class="c1">#func;                                                   \</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">tmp</span><span class="o">.</span><span class="n">substr</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">tmp</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;(&#39;</span><span class="p">));</span>                                   \
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s2">&quot;[TimeTest]&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">left</span> <span class="o">&lt;&lt;</span> <span class="n">setw</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="n">tmp</span><span class="p">;</span>                      \
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">left</span> <span class="o">&lt;&lt;</span> <span class="n">setw</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="n">duration</span> <span class="o">&lt;&lt;</span> <span class="s2">&quot;us&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>                 \
<span class="c1">#else</span>
<span class="c1">#define _T(func) func;</span>
<span class="c1">#endif</span>

<span class="o">...</span>
<span class="n">void</span> <span class="n">run_CNN</span><span class="p">(</span><span class="n">DPUTask</span> <span class="o">*</span><span class="n">taskConv</span><span class="p">,</span> <span class="n">Mat</span> <span class="n">img</span><span class="p">)</span>
<span class="p">{</span>
  <span class="o">//</span> <span class="n">Get</span> <span class="n">the</span> <span class="n">output</span> <span class="n">Tensor</span>
  <span class="n">int8_t</span> <span class="o">*</span><span class="n">outAddr</span> <span class="o">=</span> <span class="p">(</span><span class="n">int8_t</span> <span class="o">*</span><span class="p">)</span><span class="n">dpuGetOutputTensorAddress</span><span class="p">(</span><span class="n">taskConv</span><span class="p">,</span> <span class="n">CONV_OUTPUT_NODE</span><span class="p">);</span>
  <span class="o">//</span> <span class="n">Get</span> <span class="n">size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">output</span> <span class="n">Tensor</span>
  <span class="nb">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">dpuGetOutputTensorSize</span><span class="p">(</span><span class="n">taskConv</span><span class="p">,</span> <span class="n">CONV_OUTPUT_NODE</span><span class="p">);</span>
  <span class="o">//</span> <span class="n">Get</span> <span class="n">channel</span> <span class="n">count</span> <span class="n">of</span> <span class="n">the</span> <span class="n">output</span> <span class="n">Tensor</span>
  <span class="nb">int</span> <span class="n">channel</span> <span class="o">=</span> <span class="n">dpuGetOutputTensorChannel</span><span class="p">(</span><span class="n">taskConv</span><span class="p">,</span> <span class="n">CONV_OUTPUT_NODE</span><span class="p">);</span>
  <span class="o">//</span> <span class="n">Get</span> <span class="n">scale</span> <span class="n">of</span> <span class="n">the</span> <span class="n">output</span> <span class="n">Tensor</span>
  <span class="nb">float</span> <span class="n">out_scale</span> <span class="o">=</span> <span class="n">dpuGetOutputTensorScale</span><span class="p">(</span><span class="n">taskConv</span><span class="p">,</span> <span class="n">CONV_OUTPUT_NODE</span><span class="p">);</span>
  <span class="o">...</span>
  <span class="n">_T</span><span class="p">(</span><span class="n">dpuSetInputImage2</span><span class="p">(</span><span class="n">taskConv</span><span class="p">,</span> <span class="n">CONV_INPUT_NODE</span><span class="p">,</span> <span class="n">img</span><span class="p">));</span>
  <span class="o">...</span>
  <span class="n">_T</span><span class="p">(</span><span class="n">dpuRunTask</span><span class="p">(</span><span class="n">taskConv</span><span class="p">));</span>
  <span class="o">...</span>
  <span class="o">//</span> <span class="n">Calculate</span> <span class="n">softmax</span> <span class="n">on</span> <span class="n">CPU</span> <span class="ow">and</span> <span class="n">show</span> <span class="n">TOP5</span> <span class="n">classification</span> <span class="n">result</span>
  <span class="n">_T</span><span class="p">(</span><span class="n">dpuRunSoftmax</span><span class="p">(</span><span class="n">outAddr</span><span class="p">,</span> <span class="n">softmax</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">size</span><span class="o">/</span><span class="n">channel</span><span class="p">,</span> <span class="n">out_scale</span><span class="p">));</span>
  <span class="n">TopK</span><span class="p">(</span><span class="n">softmax</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">kinds</span><span class="p">);</span>
  <span class="o">...</span>
<span class="p">}</span>

<span class="o">...</span>

<span class="n">void</span> <span class="n">classifyEntry</span><span class="p">(</span><span class="n">DPUKernel</span> <span class="o">*</span><span class="n">kernelConv</span><span class="p">)</span>
<span class="p">{</span>

<span class="o">...</span>
<span class="c1">#define DPU_MODE_NORMAL 0</span>
<span class="c1">#define DPU_MODE_PROF   1</span>
<span class="c1">#define DPU_MODE_DUMP   2</span>

    <span class="o">/*</span> <span class="n">Create</span> <span class="n">DPU</span> <span class="n">Tasks</span> <span class="k">for</span> <span class="n">CONV</span>  <span class="o">*/</span>
    <span class="n">DPUTask</span> <span class="o">*</span><span class="n">taskConv</span> <span class="o">=</span> <span class="n">dpuCreateTask</span><span class="p">(</span><span class="n">kernelConv</span><span class="p">,</span> <span class="n">DPU_MODE_NORMAL</span><span class="p">);</span> <span class="o">//</span> <span class="n">profiling</span> <span class="ow">not</span> <span class="n">enabled</span>
    <span class="o">//</span><span class="n">DPUTask</span> <span class="o">*</span><span class="n">taskConv</span> <span class="o">=</span> <span class="n">dpuCreateTask</span><span class="p">(</span><span class="n">kernelConv</span><span class="p">,</span> <span class="n">DPU_MODE_PROF</span><span class="p">);</span> <span class="o">//</span> <span class="n">profiling</span> <span class="n">enabled</span>
    <span class="o">//</span><span class="n">enable</span> <span class="n">profiling</span>
    <span class="o">//</span><span class="nb">int</span> <span class="n">res1</span> <span class="o">=</span> <span class="n">dpuEnableTaskProfile</span><span class="p">(</span><span class="n">taskConv</span><span class="p">);</span>
    <span class="o">//</span><span class="k">if</span> <span class="p">(</span><span class="n">res1</span><span class="o">!=</span><span class="mi">0</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;ERROR IN ENABLING TASK PROFILING FOR CONV KERNEL</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>

<span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Be sure to have generated the <code class="docutils literal notranslate"><span class="pre">dpu_*.elf</span></code> file -after the CNN quantization process- with the <code class="docutils literal notranslate"><span class="pre">vai_c_caffe</span></code> compiler using the following flag <code class="docutils literal notranslate"><span class="pre">--options</span> <span class="pre">&quot;{'mode':'normal'}&quot;</span></code>.</p>
<p>As reported in the <a class="reference external" href="files/alexnet_zcu102/log/logfile_target_dnndk_baseline.txt">logfile_target_dnndk_baseline.txt</a>, at run time execution you will see something like this for each input image (1 us = 1e-6 s):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./fps_alexnetBNnoLRN_method1 1
now running ./fps_alexnetBNnoLRN_method1 1
total image : 1
[TimeTest]dpuSetInputImage              467       us
[TimeTest]dpuRunTask                    11105     us
[TimeTest]dpuRunSoftmax                 354       us
[TimeTest]TopK                          3         us
</pre></div>
</div>
<p>summing all together this is equivalent to 11.92ms, which corresponds to a frame rate of 83.82Hz.</p>
</div>
<div class="section" id="second-method">
<h3>4.1.2 Second Method<a class="headerlink" href="#second-method" title="Permalink to this headline">¶</a></h3>
<p>The second profiling method is explained in Chapter 8 at Section “Fine-Grained Profiling” on the <a class="reference external" href="https://www.xilinx.com/support/documentation/sw_manuals/vitis_ai/1_2/ug1414-vitis-ai.pdf">Vitis AI User Guide UG1414 v1.2</a>.</p>
<p>This is indeed the real profiling and it requires the <code class="docutils literal notranslate"><span class="pre">dpu_*.elf</span></code> file to be generated by the <code class="docutils literal notranslate"><span class="pre">vai_c_caffe</span></code> compiler with the following flag <code class="docutils literal notranslate"><span class="pre">--options</span> <span class="pre">&quot;{'mode':'debug'}&quot;</span></code>.  Furthermore, you have to modify the C++ code
in the <code class="docutils literal notranslate"><span class="pre">classifyEntry()</span></code> subroutine as illustrated in the next fragment take from <a class="reference external" href="files/alexnet_zcu102/baseline/src/fps_main_method2.cc">fps_main_method2.cc</a> file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="c1">#define SHOWTIME</span>

<span class="n">void</span> <span class="n">classifyEntry</span><span class="p">(</span><span class="n">DPUKernel</span> <span class="o">*</span><span class="n">kernelConv</span><span class="p">)</span>
<span class="p">{</span>
<span class="o">...</span>

    <span class="o">//</span><span class="n">DPUTask</span> <span class="o">*</span><span class="n">taskConv</span> <span class="o">=</span> <span class="n">dpuCreateTask</span><span class="p">(</span><span class="n">kernelConv</span><span class="p">,</span> <span class="n">DPU_MODE_NORMAL</span><span class="p">);</span> <span class="o">//</span> <span class="n">profiling</span> <span class="ow">not</span> <span class="n">enabled</span>
    <span class="n">DPUTask</span> <span class="o">*</span><span class="n">taskConv</span> <span class="o">=</span> <span class="n">dpuCreateTask</span><span class="p">(</span><span class="n">kernelConv</span><span class="p">,</span> <span class="n">DPU_MODE_PROF</span><span class="p">);</span> <span class="o">//</span> <span class="n">profiling</span> <span class="n">enabled</span>
    <span class="nb">int</span> <span class="n">res1</span> <span class="o">=</span> <span class="n">dpuEnableTaskProfile</span><span class="p">(</span><span class="n">taskConv</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">res1</span><span class="o">!=</span><span class="mi">0</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;ERROR IN ENABLING TASK PROFILING FOR CONV KERNEL</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
<span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
<p>After having cross compiled the application and running it on the target board, at run time execution you will see something like this
(which is similar to a <a class="reference external" href="https://web.eecs.umich.edu/~sugih/pointers/gprof_quick.html">gprof</a> report):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>DNNDK] Performance profile - DPU Kernel &quot;alexnetBNnoLRN_0&quot; DPU Task &quot;alexnetBNnoLRN_0-0&quot;
=====================================================================================================
  ID                       NodeName Workload(MOP) Mem(MB) RunTime(ms) Perf(GOPS) Utilization    MB/S
   1                          conv1       210.830    0.26       1.055      199.8        16.3%   245.2
   2                          conv2       895.795    0.70       0.953      940.0        76.5%   734.9
   3                          conv3       299.041    0.95       0.343      871.8        71.0%  2783.5
   4                          conv4       448.561    1.40       0.508      883.0        71.9%  2750.9
   5                          conv5       299.041    0.92       0.349      856.9        69.7%  2635.5
   6                            fc6        75.497   36.09       5.327       14.2         1.2%  6774.3
   7                            fc7        33.554   16.08       2.338       14.4         1.2%  6877.7
   8                            fc8         0.016    0.01       0.014        1.2         0.1%   845.5

                Total Nodes In Avg:
                                All      2262.336   59.15      10.887      207.8        16.9%  5433.1
=====================================================================================================
</pre></div>
</div>
<p>The runtime execution is aligned with method1 -although more accurate (having less overhead)- and shows a runtime execution of 10.87ms, which corresponds to a frame rate of ~92Hz.</p>
<p>Note also that this fine-grained profiling shows you the following parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Workload(MOP)</span></code>: Computation workload (MAC indicates two operations);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Mem(MB)</span></code>: Memory size for code, parameter, and feature map for this DPU node;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RunTime(ms)</span></code>: The execution time in unit of millisecond (ms);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Perf(GOPS)</span></code>: The DPU performance in unit of GOP per second, given by <code class="docutils literal notranslate"><span class="pre">Workload(MOP)/RunTime(ms)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Utilization</span></code>: The DPU utilization in percent (%);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MB/S</span></code>: The average DDR memory access bandwidth, given by <code class="docutils literal notranslate"><span class="pre">Mem(MB)/Runtime(ms)</span></code>.</p></li>
</ul>
</div>
<div class="section" id="third-method">
<h3>4.1.3 Third Method<a class="headerlink" href="#third-method" title="Permalink to this headline">¶</a></h3>
<p>In the third method the DPU elapsed time - including image preprocessing running on ARM CPU - is measured with the following fragment of C++ code in the <code class="docutils literal notranslate"><span class="pre">classifyEntry()</span></code> subroutine from <a class="reference external" href="files/alexnet_zcu102/baseline/src/fps_main_method3.cc">fps_main_method3.cc</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="c1">#define SHOWTIME</span>

<span class="o">...</span>

<span class="c1">#include &lt;chrono&gt;</span>
<span class="n">auto</span> <span class="n">_start</span> <span class="o">=</span> <span class="n">system_clock</span><span class="p">::</span><span class="n">now</span><span class="p">();</span> <span class="o">//</span><span class="n">timers</span>
<span class="k">for</span> <span class="p">(</span><span class="n">auto</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">threadnum</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">){</span>
<span class="n">workers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">thread</span><span class="p">([</span><span class="o">&amp;</span><span class="p">,</span><span class="n">i</span><span class="p">]()</span> <span class="p">{</span>

  <span class="o">/*</span> <span class="n">Create</span> <span class="n">DPU</span> <span class="n">Tasks</span> <span class="k">for</span> <span class="n">CONV</span>  <span class="o">*/</span>
  <span class="n">DPUTask</span> <span class="o">*</span><span class="n">taskConv</span> <span class="o">=</span> <span class="n">dpuCreateTask</span><span class="p">(</span><span class="n">kernelConv</span><span class="p">,</span> <span class="n">DPU_MODE_NORMAL</span><span class="p">);</span> <span class="o">//</span> <span class="n">profiling</span> <span class="ow">not</span> <span class="n">enabled</span>

  <span class="k">for</span><span class="p">(</span><span class="n">unsigned</span> <span class="nb">int</span> <span class="n">ind</span> <span class="o">=</span> <span class="n">i</span>  <span class="p">;</span><span class="n">ind</span> <span class="o">&lt;</span> <span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">();</span><span class="n">ind</span><span class="o">+=</span><span class="n">threadnum</span><span class="p">)</span>
    <span class="p">{</span>

      <span class="n">Mat</span> <span class="n">img</span> <span class="o">=</span> <span class="n">imread</span><span class="p">(</span><span class="n">baseImagePath</span> <span class="o">+</span> <span class="n">images</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">ind</span><span class="p">));</span> <span class="o">//</span><span class="n">OpenCV</span> <span class="n">read</span> <span class="n">image</span>
      <span class="n">run_CNN</span><span class="p">(</span><span class="n">taskConv</span><span class="p">,</span> <span class="n">img</span><span class="p">);</span> <span class="o">//</span><span class="n">this</span> <span class="n">contains</span> <span class="n">the</span> <span class="n">image</span> <span class="n">pre</span><span class="o">-</span><span class="n">processing</span>
    <span class="p">}</span>
  <span class="o">//</span> <span class="n">Destroy</span> <span class="n">DPU</span> <span class="n">Tasks</span> <span class="o">&amp;</span> <span class="n">free</span> <span class="n">resources</span>
  <span class="n">dpuDestroyTask</span><span class="p">(</span><span class="n">taskConv</span><span class="p">);</span>
<span class="p">});</span>
<span class="p">}</span>

<span class="o">//</span> <span class="n">Release</span> <span class="n">thread</span> <span class="n">resources</span><span class="o">.</span>
<span class="k">for</span> <span class="p">(</span><span class="n">auto</span> <span class="o">&amp;</span><span class="n">w</span> <span class="p">:</span> <span class="n">workers</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">joinable</span><span class="p">())</span> <span class="n">w</span><span class="o">.</span><span class="n">join</span><span class="p">();</span>
<span class="p">}</span>

<span class="n">auto</span> <span class="n">_end</span> <span class="o">=</span> <span class="n">system_clock</span><span class="p">::</span><span class="n">now</span><span class="p">();</span>
<span class="n">auto</span> <span class="n">duration</span> <span class="o">=</span> <span class="p">(</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">microseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">_end</span> <span class="o">-</span> <span class="n">_start</span><span class="p">))</span><span class="o">.</span><span class="n">count</span><span class="p">();</span>
<span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s2">&quot;[Time]&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">duration</span> <span class="o">&lt;&lt;</span> <span class="s2">&quot;us&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
<span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s2">&quot;[FPS]&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">*</span><span class="mf">1000000.0</span><span class="o">/</span><span class="n">duration</span>  <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>

<span class="o">...</span>

<span class="n">DPUTask</span> <span class="o">*</span><span class="n">taskconv</span> <span class="o">=</span> <span class="n">dpuCreateTask</span><span class="p">(</span><span class="n">kernelconv</span><span class="p">,</span> <span class="n">DPU_MODE_NORMAL</span><span class="p">);</span> <span class="o">//</span> <span class="n">profiling</span> <span class="ow">not</span> <span class="n">enabled</span>
<span class="o">//</span><span class="n">DPUTask</span> <span class="o">*</span><span class="n">taskconv</span> <span class="o">=</span> <span class="n">dpuCreateTask</span><span class="p">(</span><span class="n">kernelconv</span><span class="p">,</span> <span class="n">DPU_MODE_PROF</span><span class="p">);</span> <span class="o">//</span> <span class="n">profiling</span> <span class="n">enabled</span>
<span class="o">//</span><span class="n">enable</span> <span class="n">profiling</span>
<span class="o">//</span><span class="nb">int</span> <span class="n">res1</span> <span class="o">=</span> <span class="n">dpuEnableTaskProfile</span><span class="p">(</span><span class="n">taskconv</span><span class="p">);</span>
<span class="o">//</span><span class="k">if</span> <span class="p">(</span><span class="n">res1</span><span class="o">!=</span><span class="mi">0</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;ERROR IN ENABLING TASK PROFILING FOR CONV KERNEL</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">);</span>
</pre></div>
</div>
<p>At run time execution you will see something like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>...
[Time]17368us
[FPS]57.5772
...
</pre></div>
</div>
<p>The effective frame rate is now 57.57Hz, as it includes also the ARM CPU cycles spent for executing SW routines to load and preprocess the input images.</p>
</div>
</div>
<div class="section" id="increasing-alexnet-performance-in-terms-of-fps">
<h2>4.2 Increasing AlexNet Performance in Terms of FPS<a class="headerlink" href="#increasing-alexnet-performance-in-terms-of-fps" title="Permalink to this headline">¶</a></h2>
<div class="section" id="multithreading">
<h3>4.2.1 Multithreading<a class="headerlink" href="#multithreading" title="Permalink to this headline">¶</a></h3>
<p>The code adopted for method 3 <a class="reference external" href="files/alexnet_zcu102/src/fps_main_method3.cc">fps_main_method3.cc</a> is the most efficient to try multithreading experiments, adding more images in input to the DPU, with the hope to increase the data rate in terms of “frames-per-second” or “fps” shortly.</p>
<p>As reported in the  <a class="reference external" href="files/alexnet_zcu102/log/logfile_target_dnndk_baseline.txt">logfile_target_dnndk_baseline.txt</a>, and illustrated in the following fragment:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">1</span>
<span class="n">now</span> <span class="n">running</span> <span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">1</span>
<span class="n">total</span> <span class="n">image</span> <span class="p">:</span> <span class="mi">1000</span>
<span class="p">[</span><span class="n">Time</span><span class="p">]</span><span class="mi">14289605</span><span class="n">us</span>
<span class="p">[</span><span class="n">FPS</span><span class="p">]</span><span class="mf">69.9809</span>

<span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">2</span>
<span class="n">now</span> <span class="n">running</span> <span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">2</span>
<span class="n">total</span> <span class="n">image</span> <span class="p">:</span> <span class="mi">1000</span>
<span class="p">[</span><span class="n">Time</span><span class="p">]</span><span class="mi">8427321</span><span class="n">us</span>
<span class="p">[</span><span class="n">FPS</span><span class="p">]</span><span class="mf">118.662</span>

<span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">3</span>
<span class="n">now</span> <span class="n">running</span> <span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">3</span>
<span class="n">total</span> <span class="n">image</span> <span class="p">:</span> <span class="mi">1000</span>
<span class="p">[</span><span class="n">Time</span><span class="p">]</span><span class="mi">7507790</span><span class="n">us</span>
<span class="p">[</span><span class="n">FPS</span><span class="p">]</span><span class="mf">133.195</span>

<span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">4</span>
<span class="n">now</span> <span class="n">running</span> <span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">4</span>
<span class="n">total</span> <span class="n">image</span> <span class="p">:</span> <span class="mi">1000</span>
<span class="p">[</span><span class="n">Time</span><span class="p">]</span><span class="mi">6866431</span><span class="n">us</span>
<span class="p">[</span><span class="n">FPS</span><span class="p">]</span><span class="mf">145.636</span>

<span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">5</span>
<span class="n">now</span> <span class="n">running</span> <span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">5</span>
<span class="n">total</span> <span class="n">image</span> <span class="p">:</span> <span class="mi">1000</span>
<span class="p">[</span><span class="n">Time</span><span class="p">]</span><span class="mi">6563955</span><span class="n">us</span>
<span class="p">[</span><span class="n">FPS</span><span class="p">]</span><span class="mf">152.347</span>

<span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">6</span>
<span class="n">now</span> <span class="n">running</span> <span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">6</span>
<span class="n">total</span> <span class="n">image</span> <span class="p">:</span> <span class="mi">1000</span>
<span class="p">[</span><span class="n">Time</span><span class="p">]</span><span class="mi">6609546</span><span class="n">us</span>
<span class="p">[</span><span class="n">FPS</span><span class="p">]</span><span class="mf">151.296</span>
</pre></div>
</div>
<p>The best performance achieves ~152fps with 5 threads in parallel. This happens because the DPU multithreading environment will instantiate 5 kernels running in parallel and loading images at a different time, thus using the DPU architecture in a more efficient way. This is almost a factor of 3 in terms of performance increase.</p>
</div>
<div class="section" id="pruning">
<h3>4.2.2 Pruning<a class="headerlink" href="#pruning" title="Permalink to this headline">¶</a></h3>
<p>Some CNNs - as <code class="docutils literal notranslate"><span class="pre">AlexNet</span></code> - have naturally a high level of redundancy and so they can be optimized with a “pruning” technique, as explained in <a class="reference external" href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/VAI-Caffe-ML-CATSvsDOGS">UG1336</a>, which means the amount of operations can be greatly reduced by pruning the CNN without detriment of its prediction accuracy. However, there are other CNNs -like <code class="docutils literal notranslate"><span class="pre">MobileNet</span></code> - which cannot be further pruned otherwise their intelligence could be destroyed.</p>
<p>When running the “pruned” <code class="docutils literal notranslate"><span class="pre">AlexNet</span></code> with 5 threads the frame rate increases to 410.77Hz, as reported in the <a class="reference external" href="files/alexnet_zcu102/log/logfile_target_dnndk_pruned.txt">logfile_target_dnndk_pruned.txt</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">5</span>
<span class="n">now</span> <span class="n">running</span> <span class="o">./</span><span class="n">fps_alexnetBNnoLRN</span> <span class="mi">5</span>
<span class="n">total</span> <span class="n">image</span> <span class="p">:</span> <span class="mi">1000</span>
<span class="p">[</span><span class="n">Time</span><span class="p">]</span><span class="mi">2434441</span><span class="n">us</span>
<span class="p">[</span><span class="n">FPS</span><span class="p">]</span><span class="mf">410.772</span>
</pre></div>
</div>
<p>whereas the average top-1 accuracy is 0.95 (it was 0.94 in the baseline, not-pruned, CNN):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">number</span> <span class="n">of</span> <span class="n">total</span> <span class="n">images</span> <span class="n">predicted</span>  <span class="mi">999</span>
<span class="n">number</span> <span class="n">of</span> <span class="n">top1</span> <span class="n">false</span> <span class="n">predictions</span>  <span class="mi">47</span>
<span class="n">number</span> <span class="n">of</span> <span class="n">top1</span> <span class="n">right</span> <span class="n">predictions</span>  <span class="mi">952</span>

<span class="n">top1</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="mf">0.95</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="profiling-fcn8-cnn-for-semantic-segmentation">
<h2>4.3 Profiling FCN8 CNN for Semantic Segmentation<a class="headerlink" href="#profiling-fcn8-cnn-for-semantic-segmentation" title="Permalink to this headline">¶</a></h2>
<p>In this Section you see how profiling the <code class="docutils literal notranslate"><span class="pre">FCN8</span></code> CNN for Semantic Segmentation trained with Keras/TensorFlow on a small dataset (which is part of the <a class="reference external" href="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/">CamVid</a>)  with RGB images of size 224x224x3, as illustrated in the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI-Tutorials/tree/VAI-KERAS-FCN8-SEMSEG">UG1445</a>.</p>
<p>To save time, you can run profiling using only one input image, as its results do not depend on the amount of input images. Due to that the archive <code class="docutils literal notranslate"><span class="pre">test1.tar</span></code> contains only one image, differently from the archive <code class="docutils literal notranslate"><span class="pre">test_images.tar</span></code>.</p>
<p>Make an archive of the <code class="docutils literal notranslate"><span class="pre">fcn8_zcu102</span></code> folder and then copy <code class="docutils literal notranslate"><span class="pre">fcn8_zcu102.tar</span></code> to your ZCU102 target board with <code class="docutils literal notranslate"><span class="pre">scp</span></code> utility: for example, assuming your target board have static IP address value of <code class="docutils literal notranslate"><span class="pre">192.168.1.40</span></code>, the command will be <code class="docutils literal notranslate"><span class="pre">scp</span> <span class="pre">./fcn8_zcu102.tar</span> <span class="pre">root&#64;192.168.1.40:~/</span></code> (password is <code class="docutils literal notranslate"><span class="pre">root</span></code>).</p>
<p>All the results are obtained by running <code class="docutils literal notranslate"><span class="pre">run_all.sh</span></code> script directly from the ZCU102 board:</p>
<p>Log files were captured for your comfort and placed in the <code class="docutils literal notranslate"><span class="pre">fcn8_zcu102/log</span></code> folder.</p>
<div class="section" id="profiling-results-with-method2">
<h3>4.3.1 Profiling results with method2<a class="headerlink" href="#profiling-results-with-method2" title="Permalink to this headline">¶</a></h3>
<p>An alternative  way to implement the method2 (fine grained profiling), which is also simpler than what done for <code class="docutils literal notranslate"><span class="pre">alexnet</span></code> example, is to avoid using the following lines of code (from the <a class="reference external" href="files/fcn8_zcu102/fcn8/src/fps_main.cc">fps_main.cc</a> C++ application file):</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">DPUTask</span> <span class="o">*</span><span class="n">taskConv</span> <span class="o">=</span> <span class="n">dpuCreateTask</span><span class="p">(</span><span class="n">kernelConv</span><span class="p">,</span> <span class="n">DPU_MODE_PROF</span><span class="p">);</span> <span class="c1">// profiling enabled</span>
<span class="c1">//enable profiling</span>
<span class="kt">int</span> <span class="n">res1</span> <span class="o">=</span> <span class="n">dpuEnableTaskProfile</span><span class="p">(</span><span class="n">taskConv</span><span class="p">);</span>
<span class="k">if</span> <span class="p">(</span><span class="n">res1</span><span class="o">!=</span><span class="mi">0</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">&quot;ERROR IN ENABLING TASK PROFILING FOR CONV KERNEL</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
</pre></div>
</div>
<p>and just use only the following line:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">DPUTask</span> <span class="o">*</span><span class="n">taskConv</span> <span class="o">=</span> <span class="n">dpuCreateTask</span><span class="p">(</span><span class="n">kernelConv</span><span class="p">,</span> <span class="n">DPU_MODE_NORMAL</span><span class="p">);</span> <span class="c1">// profiling not enabled</span>
</pre></div>
</div>
<p>then you enable the <code class="docutils literal notranslate"><span class="pre">mode</span> <span class="pre">=</span> <span class="pre">profile</span></code> with the <code class="docutils literal notranslate"><span class="pre">dexplorer</span></code> DNNDK utility (running on the target board), as illustrated in this fragment of code taken from the <a class="reference external" href="files/fcn8_zcu102/run_on_zcu102.sh">run_on_zcu102.sh</a> shell script, and just lunch the application:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>dexplorer -m profile <span class="c1"># enable profiling</span>
./dbg_fcn8 <span class="m">1</span>         <span class="c1"># launch the application</span>
</pre></div>
</div>
<p>As already done previously for the <code class="docutils literal notranslate"><span class="pre">alexnet</span></code> example, the <code class="docutils literal notranslate"><span class="pre">dbg_dpu_fcn8.elf</span></code> file was generated by the <code class="docutils literal notranslate"><span class="pre">vai_c_tensorflow</span></code> compiler with the flag <code class="docutils literal notranslate"><span class="pre">--options</span> <span class="pre">&quot;{'mode':'debug'}&quot;</span></code>.</p>
<p>After having cross compiled the application and running it on the target board, as reported in the <a class="reference external" href="files/fcn8_zcu102/log/logfile_target_fcn8.txt">logfile_target_fcn8.txt</a>, at run time execution of <code class="docutils literal notranslate"><span class="pre">fcn8</span></code>
you will see something like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[DNNDK] Performance profile - DPU Kernel &quot;fcn8&quot; DPU Task &quot;fcn8-0&quot;
=====================================================================================================
  ID                       NodeName Workload(MOP) Mem(MB) RunTime(ms) Perf(GOPS) Utilization    MB/S
   1       block1_conv1_convolution       173.408    3.22       0.753      230.3        18.7%  4273.2
   2       block1_conv2_convolution      3699.376    3.88       3.251     1137.9        92.6%  1193.5
   3       block2_conv1_convolution      1849.688    2.37       1.646     1123.7        91.5%  1442.8
   4       block2_conv2_convolution      3699.376    2.07       3.248     1139.0        92.7%   636.3
   5       block3_conv1_convolution      1849.688    1.44       1.647     1123.1        91.4%   872.9
   6       block3_conv2_convolution      3699.376    2.11       3.250     1138.3        92.6%   648.9
   7       block3_conv3_convolution      3699.376    1.53       3.249     1138.6        92.7%   472.0
   8       block4_conv1_convolution      1849.688    1.71       1.871      988.6        80.5%   914.9
   9       block4_conv2_convolution      3699.376    3.04       3.719      994.7        81.0%   816.8
  10       block4_conv3_convolution      3699.376    2.75       3.720      994.5        80.9%   739.1
  11           pool4_11_convolution         2.408    0.10       0.030       80.3         6.5%  3483.8
  12       block5_conv1_convolution       924.844    2.45       0.956      967.4        78.7%  2565.3
  13 conv2d_transpose_2_conv2d_transpose    0.226    0.01       0.023        9.8         0.8%   556.6
  14       block5_conv2_convolution       924.844    2.45       0.956      967.4        78.7%  2565.3
  15           pool3_11_convolution         4.817    0.21       0.046      104.7         8.5%  4665.9
  16       block5_conv3_convolution       924.844    2.38       0.957      966.4        78.6%  2487.4
  17              conv6_convolution      1258.815   12.31       3.112      404.5        32.9%  3955.9
  18              conv7_convolution        25.690    0.31       0.088      291.9        23.8%  3488.8
  19 conv2d_transpose_1_conv2d_transpose    9.634    0.13       0.048      200.7        16.3%  2660.8
  20                add_layer_add_1         0.000    0.03       0.029        0.0         0.0%   998.3
  21 conv2d_transpose_3_conv2d_transpose   14.451    0.61       0.281       51.4         4.2%  2169.8

                Total Nodes In Avg:
                                All     32009.303   47.31      32.880      973.5        79.2%  1438.9
=====================================================================================================
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="experiments-with-vart-python-and-c-apis">
<h1>5 Experiments with VART Python and C++ APIs<a class="headerlink" href="#experiments-with-vart-python-and-c-apis" title="Permalink to this headline">¶</a></h1>
<p>Vitis AI Run Time - shortly named VART - enables applications to use the unified high-level runtime API for both cloud and edge. In fact the DNNDK API are necessary to support the Legacy DNNDK examples for edge and are not portable at all on the cloud (at the time there was not yet any Vitis AI). If you use VART, the same application - as it is - can be targeted to either an edge or an Alveo card. Furthermore - and much more important - VART API abstract the CNN features at much higher level than the DNNDK API, which means a much simpler C++ code to be managed.</p>
<p>The first action you have to do about VART is reading the instructions of <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/tree/master/demo/VART/README">Vitis AI VART README.md</a>.</p>
<div class="section" id="alexnet-cnn">
<h2>5.1 AlexNet CNN<a class="headerlink" href="#alexnet-cnn" title="Permalink to this headline">¶</a></h2>
<p>You can find the most recent implementation of AlexNet CNN using VART APIs in this Vitis AI 1.3 <a class="reference external" href="https://github.com/Xilinx/Vitis-Tutorials/tree/master/Machine_Learning/Design_Tutorials/01-caffe_cats_vs_dogs">01-caffe_cats_vs_dogs </a> tutorial.</p>
</div>
<div class="section" id="fcn8-and-fcn8ups-cnns">
<h2>5.2 FCN8 and FCN8UPS  CNNs<a class="headerlink" href="#fcn8-and-fcn8ups-cnns" title="Permalink to this headline">¶</a></h2>
<p>You can find the most recent implementation of FCN8 and FCN8UPS CNNs using VART APIs in this Vitis AI 1.3 <a class="reference external" href="https://github.com/Xilinx/Vitis-Tutorials/tree/master/Machine_Learning/Design_Tutorials/05-Keras_FCN8_UNET_segmentation">05-Keras_FCN8_UNET_segmentation</a> tutorial.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
<!-- Atalwar: Moved the footer code to layout.html to resolve conflict with the Xilinx template -->
</footer>

        </div>
      </div>


	  <!-- Sphinx Page Footer block -->
  

  <hr/>

  <div role="contentinfo" class="copyright">
    <p class="footerinfo">

    </p>
	<br>
  </div>
      </div>
    </section>


  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

   <script type="text/javascript">
    jQuery(function() { Search.loadIndex("searchindex.js"); });
  </script>

  <script type="text/javascript" id="searchindexloader"></script>


  
  
    
  



  <!--  Xilinx template footer block -->
							</div>
						</div>
					</div>
				</div>
				<div class="xilinxExperienceFragments experiencefragment aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
					<div class="xf-content-height">
						<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 ">
							<div class="footer parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
								<noindex>
                  <!-- make footer fixed - NileshP -->
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
                  <!-- make footer fixed NileshP-->
									<footer>
										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">
													<div class="row">
														<div class="footerSocial parbase">
															<div class="col-md-push-6 col-lg-push-6 col-md-6 col-lg-6">
																<ul class="list-inline pull-right social-menu">
																	<li>
																		<a href="https://www.linkedin.com/company/xilinx">
																		<span class="linkedin icon"></span>
																		<span class="sr-only">Connect on LinkedIn</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.twitter.com/XilinxInc">
																		<span class="twitter icon"></span>
																		<span class="sr-only">Follow us on Twitter</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.facebook.com/XilinxInc">
																		<span class="facebook icon"></span>
																		<span class="sr-only">Connect on Facebook</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.youtube.com/XilinxInc">
																		<span class="youtube icon"></span>
																		<span class="sr-only">Watch us on YouTube</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.xilinx.com/registration/subscriber-signup.html">
																		<span class="newsletter icon"></span>
																		<span class="sr-only">Subscribe to Newsletter</span>
																		</a>
																	</li>
																</ul>
															</div>
														</div>
														<div class="col-md-pull-6 col-lg-pull-6 col-md-6 col-lg-6">
															<span class="copyright">
                                  
                                  &copy; 2020–2021, Xilinx, Inc.
                              </span>
															<ul class="list-inline sub-menu">
																<li>
																	<a href="https://www.xilinx.com/about/privacy-policy.html">Privacy</a>
																</li>
																<li>
																	<a href="https://www.xilinx.com/about/legal.html">Legal</a>
																</li>
																<li>
																	<a href="https://www.xilinx.com/about/contact.html">Contact</a>
																</li>
															</ul>
														</div>
													</div>
												</div>
											</div>
										</div>
									</footer>
								</noindex>
							</div>
						</div>
					</div>
				</div>
				<div class="quicklinks parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
					<noindex>
						<span class="quickLinks">
							<ul>
								<li>
									<a href="#top" class="btn backToTop">
									<span class="fas fa-angle-up" aria-hidden="true"></span>
									</a>
								</li>
							</ul>
						</span>
					</noindex>
				</div>
			</div>
		</div>
		<script>window.CQ = window.CQ || {}</script>
		<script src="https://static.cloud.coveo.com/searchui/v2.4382/js/CoveoJsSearch.Lazy.min.js"></script>
		<script>
			var underscoreSetup = function () {
			  _.templateSettings.interpolate = /\{\{=([^-][\S\s]+?)\}\}/g;
			  _.templateSettings.evaluate = /\{\{([^-=][\S\s]+?)\}\}/g;
			  _.templateSettings.escape = /\{\{-([^=][\S\s]+?)\}\}/g;
			}

			underscoreSetup();
		</script>
	</body>
</html>