


<!DOCTYPE HTML>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
	<head>
		<meta charset="utf-8">
		
		<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>
		<link rel="stylesheet" href="https://static.cloud.coveo.com/searchui/v2.4382/css/CoveoFullSearch.css"/>
		<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
		<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
		<meta name="description"/>
		<meta name="keywords"/>
		<meta property="og:title" content=""/>
		<meta property="og:description"/>
		<!-- favicon -->
		<link rel="icon" type="image/vnd.microsoft.icon" href="../../../_static/favicon.ico"/>
		<link rel="shortcut icon" type="image/vnd.microsoft.icon" href="../../../_static/favicon.ico"/>
		<!-- Fonts -->
		<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet" type="text/css"/>

  
  
  
  

  
      <script type="text/javascript" src="../../../_static/js/jquery.min.js"></script>
	  <script type="text/javascript" src="../../../_static/js/gtm.js"></script>
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/d3dd8c60ed.js"></script>
    <script type="text/javascript" src="../../../_static/js/common-ui-all.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/header-footer.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/jquery-ui.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/CoveoJsSearch.Lazy.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/linkid.js"></script>
    <script type="text/javascript" src="../../../_static/js/Searchbox.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/common-ui-all.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/header-footer.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/pro.min.css" media="all" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
	</head>
	<body>
		<div class="xilinx-bs3"/>
		<div class="root responsivegrid">
			<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 aem-Grid--large--16 aem-Grid--xlarge--16 aem-Grid--xxlarge--16 aem-Grid--xxxlarge--16 ">
				<div class="xilinxExperienceFragments experiencefragment aem-GridColumn aem-GridColumn--default--12">
					<div class="xf-content-height">
						<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 ">
							<div class="header parbase aem-GridColumn aem-GridColumn--default--12">
								<noindex>
									<header data-component="header">
										<nav class="navbar navbar-default aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid main-nav">
													<div class="row">
														<div class="col-xs-12">
															<div class="logo-column">
																<div class="logo">
																	<a href="https://www.xilinx.com/">
																	<img src="https://www.xilinx.com/etc.clientlibs/site/clientlibs/xilinx/all/resources/imgs/header/xilinx-header-logo.svg" title="Xilinx Inc"/>
																	</a>
																</div>
															</div>
															<div class="navbar-column">
																<div class="navbar navbar-collapse collapse" id="xilinx-main-menu">
																	<div class="mobile-search-container">
																		<div id="headerSearchBox" class="headerSearch"
																			data-component="header-search"
																			data-redirect-if-empty="false"
																			data-coveo-access-token="xxa237d4dd-f0aa-47fc-9baa-af9121851b33"
																			data-coveo-organization-id="xilinxcomprode2rjoqok">
																			<div class='coveo-search-section'>
																				<div class="CoveoAnalytics" data-search-hub="Site"></div>
																				<ul class="dropdown-menu options">
																					<li class="option" data-label="All" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-search-hub="Site">
																						<a href="#">
																						All</a>
																					</li>
																					<li data-label="Silicon Devices" data-action-link="https://www.xilinx.com//products/silicon-devices/si-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Silicon Devices</a>
																					</li>
																					<li data-label="Boards and Kits" data-action-link="https://www.xilinx.com//products/boards-and-kits/bk-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Boards and Kits</a>
																					</li>
																					<li data-label="Intellectual Property" data-action-link="https://www.xilinx.com//products/intellectual-property/ip-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Intellectual Property</a>
																					</li>
																					<li data-label="Support" class="option" data-action-link="https://www.xilinx.com/search/support-keyword-search.html" data-search-hub="Support">
																						<a href="#">
																						Support</a>
																						<ul>
																							<li data-label="Documentation" data-action-link="https://www.xilinx.com//support/documentation-navigation/documentation-keyword-search.html" data-search-hub="Document">
																								<a href="#">
																								Documentation</a>
																							</li>
																							<li data-label="Knowledge Base" data-action-link="https://www.xilinx.com//support/answer-navigation/answer-keyword-search.html" data-search-hub="AnswerRecord">
																								<a href="#">
																								Knowledge Base</a>
																							</li>
																							<li data-label="Community Forums" data-action-link="https://www.xilinx.com/search/forums-keyword-search.html" data-search-hub="Forums">
																								<a href="#">
																								Community Forums</a>
																							</li>
																						</ul>
																					</li>
																					<li data-label="Partners" data-action-link="https://www.xilinx.com//alliance/member-keyword-search.html" data-search-hub="Partner">
																						<a href="#">
																						Partners</a>
																					</li>
																					<li data-label="Videos" data-action-link="https://www.xilinx.com/video/video-keyword-search.html" data-search-hub="Video">
																						<a href="#">
																						Videos</a>
																					</li>
																					<li data-label="Press" data-action-link="https://www.xilinx.com/search/press-keyword-search.html" data-search-hub="Press">
																						<a href="#">
																						Press</a>
																					</li>
																				</ul>
																				<a href="#" class="btn dropdown-toggle value" data-toggle="dropdown"></a>
																				<div class="CoveoSearchbox" data-id="coveosearchbox" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-placeholder="Search Xilinx"></div>
																			</div>
																		</div>
																	</div>
																	<ul class="nav navbar-nav nav-justified">
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/applications.html">
																			Applications</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/products/silicon-devices.html">
																			Products</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://developer.xilinx.com/">
																			Developers</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/support.html">
																			Support</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/about/company-overview.html">
																			About</a>
																		</li>
																	</ul>
																</div>
															</div>
															<script type="text/javascript" src="../../../_static/js/gtm.js"></script>
															<!--<div class="mini-nav">
																<button type="button" data-function="xilinx-mobile-menu" id="nav-toggle" class="navbar-toggle collapsed visible-xs-block" aria-expanded="false">
																<span></span>
																<span></span>
																<span></span>
																<span></span>
																</button>
																<ul class="list-inline">
																	<li class="dropdown user-menu">
																		<button data-toggle="dropdown">
																		<span class="sr-only">Account</span>
																		<span class="fas fa-user"></span>
																		</button>
																		<ul class="dropdown-menu">
																			<li>
																				<a href="https://www.xilinx.com/myprofile/subscriptions.html">
																				My Account</a>
																			</li>
																			<li>
																				<a href="https://www.xilinx.com/registration/create-account.html">
																				Create Account</a>
																			</li>
																			<li>
																				<a href="https://www.xilinx.com/bin/protected/en/signout">
																				Sign Out</a>
																			</li>
																		</ul>
																	</li>
																	<li class="hidden-xs">
																		<button data-function="search-toggle">
																		<span class="sr-only">Search</span>
																		<span class="far fa-search"></span>
																		</button>
																	</li>
																</ul>
															</div>
															-->
															<div class="search-container">
																<div id="headerSearchBox" class="headerSearch"
																	data-component="header-search"
																	data-redirect-if-empty="false"
																	data-coveo-access-token="xxa237d4dd-f0aa-47fc-9baa-af9121851b33"
																	data-coveo-organization-id="xilinxcomprode2rjoqok">
																	<div class='coveo-search-section'>
																		<div class="CoveoAnalytics" data-search-hub="Site"></div>
																		<ul class="dropdown-menu options">
																			<li class="option" data-label="All" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-search-hub="Site">
																				<a href="#">
																				All</a>
																			</li>
																			<li data-label="Silicon Devices" data-action-link="https://www.xilinx.com/products/silicon-devices/si-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Silicon Devices</a>
																			</li>
																			<li data-label="Boards and Kits" data-action-link="https://www.xilinx.com/products/boards-and-kits/bk-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Boards and Kits</a>
																			</li>
																			<li data-label="Intellectual Property" data-action-link="https://www.xilinx.com/products/intellectual-property/ip-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Intellectual Property</a>
																			</li>
																			<li data-label="Support" class="option" data-action-link="https://www.xilinx.com/search/support-keyword-search.html" data-search-hub="Support">
																				<a href="#">
																				Support</a>
																				<ul>
																					<li data-label="Documentation" data-action-link="https://www.xilinx.com/support/documentation-navigation/documentation-keyword-search.html" data-search-hub="Document">
																						<a href="#">
																						Documentation</a>
																					</li>
																					<li data-label="Knowledge Base" data-action-link="https://www.xilinx.com/support/answer-navigation/answer-keyword-search.html" data-search-hub="AnswerRecord">
																						<a href="#">
																						Knowledge Base</a>
																					</li>
																					<li data-label="Community Forums" data-action-link="https://www.xilinx.com/search/forums-keyword-search.html" data-search-hub="Forums">
																						<a href="#">
																						Community Forums</a>
																					</li>
																				</ul>
																			</li>
																			<li data-label="Partners" data-action-link="https://www.xilinx.com/alliance/member-keyword-search.html" data-search-hub="Partner">
																				<a href="#">
																				Partners</a>
																			</li>
																			<li data-label="Videos" data-action-link="https://www.xilinx.com/video/video-keyword-search.html" data-search-hub="Video">
																				<a href="#">
																				Videos</a>
																			</li>
																			<li data-label="Press" data-action-link="https://www.xilinx.com/search/press-keyword-search.html" data-search-hub="Press">
																				<a href="#">
																				Press</a>
																			</li>
																		</ul>
																		<a href="#" class="btn dropdown-toggle value" data-toggle="dropdown"></a>
																		<div class="CoveoSearchbox" data-id="coveosearchbox" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-placeholder="Search Xilinx"></div>
																	</div>
																</div>
																<button data-function="search-toggle">
																<span class="sr-only">Search</span>
																<span class="far fa-times"></span>
																</button>
															</div>
														</div>
													</div>
												</div>
											</div>
										</nav>
									</header>
								</noindex>
							</div>
						</div>
					</div>
				</div>
				<div class="parsys aem-GridColumn--xxxlarge--none aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
						<div class="container-fluid">
							<div class="row">
							<div class="col-xs-12">
   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> Vitis チュートリアル
          

          
          </a>

          
            
            
              <div class="version">
                2020.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

      
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
            
            
            
              
            
            
              <p class="caption"><span class="caption-text">English version</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/master/docs/index.html">Master</a></li>
</ul>
<p class="caption"><span class="caption-text">入門</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis/README.html">Vitis フロー 101 チュートリアル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis_HLS/README.html">Vitis HLS の解析および最適化</a></li>
</ul>
<p class="caption"><span class="caption-text">機械学習 (英語版)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Introduction to Machine Learning with Vitis AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../README.html#design-tutorials">Design Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../README.html#feature-tutorials">Feature Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">アクセラレーション</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html">Vitis ハードウェア アクセラレータの概要</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html#id1">設計チュートリアル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html#id2">機能チュートリアル</a></li>
</ul>
<p class="caption"><span class="caption-text">AI エンジン開発 (英語版)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../AI_Engine_Development/README.html">Design Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../AI_Engine_Development/README.html#feature-tutorials">Feature Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">プラットフォーム作成チュートリアル</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/README.html">プラットフォームの作成</a></li>
</ul>
<p class="caption"><span class="caption-text">XRT および Vitis システム最適化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/README.html">設計チュートリアル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/README.html#id2">機能チュートリアル</a></li>
</ul>
<p class="caption"><span class="caption-text">バージョン</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/2020-1/docs/README.html">2020.1</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Xilinx/Vitis-Tutorials/blob/Vitis-Tutorials-2019.2-Hotfix1/README.md">2019.2</a></li>
</ul>

            
			
			<p class="caption"><span class="caption-text">This Page</span></p>
				<ul class="current">
				  <li class="toctree-l1"><a href="../../../_sources/Machine_Learning/Feature_Tutorials/03-edge-to-cloud/README.md.txt"
						rel="nofollow">Show Source</a></li>
				</ul>
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Vitis チュートリアル</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Current Status</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/Machine_Learning/Feature_Tutorials/03-edge-to-cloud/README.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <table>
 <tr>
   <td align="center"><img src="https://www.xilinx.com/content/dam/xilinx/imgs/press/media-kits/corporate/xilinx-logo.png" width="30%"/><h1>Vitis AI Tutorials</h1>
   </td>
 </tr>
 <tr>
 <td align="center"><h3>Moving Seamlessly Between Edge and Cloud with Vitis AI</h3>
 </td>
 </tr>
</table><p>This tutorial shows you how to compile and run the same identical design and application code on either the Alveo U50 data center accelerator card or the Zynq® UltraScale+™ MPSoC ZCU102 evaluation board.</p>
<p>The virtually seamless transition between Edge and Cloud is made possible by the new Vitis™ AI RunTime (VART), introduced in the 1.1 release of Vitis AI.</p>
<p>The dataset used in this example is <a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/data">Kaggle’s dogs-vs-cats</a>.</p>
<div class="section" id="current-status">
<h1>Current Status<a class="headerlink" href="#current-status" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Tested with Vitis AI 1.2 on Alveo U50 &amp; ZCU102</p></li>
</ul>
</div>
<div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>We will run the following steps:</p>
<ol class="simple">
<li><p>Download and preparation of the Kaggle dogs-vs-cats dataset.</p></li>
</ol>
<ul class="simple">
<li><p>Training and evaluation of a simple custom CNN using TensorFlow’s built-in version of Keras.</p></li>
<li><p>Conversion of the saved Keras checkpoint (HDF5 format) to TensorFlow checkpoint format.</p></li>
<li><p>Removal of the training nodes and conversion of the graph variables to constants (..often referred to as ‘freezing the graph’).</p></li>
<li><p>Evaluation of the frozen model using the dogs-vs-cats test dataset.</p></li>
<li><p>Quantization of the frozen model using the Xilinx® quantizer provided as part of Vitis AI.</p></li>
<li><p>Evaluation of the quantized model using the dogs-vs-cats test dataset.</p></li>
<li><p>Compilation of the quantized model for execution on either the Alveo U50 or the ZCU102.</p></li>
<li><p>Execution of the network with the provided Python scripts.</p></li>
</ul>
<p>The complete flow and the tools used at each step is shown in the figure below:</p>
<p align="center">
  <img width="250" height="500" src="files/img/fig3.png">
</p><div class="section" id="the-kaggle-dogs-vs-cats-dataset">
<h2>The Kaggle Dogs-vs-Cats Dataset<a class="headerlink" href="#the-kaggle-dogs-vs-cats-dataset" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/data">Kaggle dog-vs-cats dataset</a> consists of 25000 images of varying dimensions, divided into the two classes of <em>cat</em> and <em>dog</em>. Each image is intrinsically labelled or classified by its filename, for example the image with filename <em>cat.12.jpg</em> is obviously of class <em>cat</em>.</p>
<p>There is also a set of labelled images which were part of the original Kaggle dogs-vs-cats challenge, but we will ignore this set and only use the 25000 images that are contained in the train.zip archive.</p>
<p>The 25000 images are all resized to 200 x 250 pixels and then divided into one of the train, validation or test datasets. They are further sub-divided into class folders to make the folder structure compatible with the Keras <code class="docutils literal notranslate"><span class="pre">.flow_from_directory()</span></code> method.</p>
<p>The size of 200 x 250 pixels was chosen after studying the distribution of the aspect ratios in the dataset and to keep training times reasonable.</p>
<p><img alt="folders" src="../../../_images/fig11.png" /></p>
<br></div>
<div class="section" id="the-convolution-neural-network">
<h2>The Convolution Neural Network<a class="headerlink" href="#the-convolution-neural-network" title="Permalink to this headline">¶</a></h2>
<p>The customcnn.py script uses the Keras Functional API to describe the simple CNN. It is a fully-convolutional network and has no fully-connected/dense layers. There are also no pooling layers, data reduction is achieved by using convolutional layers that have strides greater than one.</p>
<p>The CNN has deliberately been kept simple (so the expected prediction accuracy will not be much higher than approximately 92%. To reduce overfitting, batch normalization, dropout and L2 kernel regularization have been used.</p>
<p><img alt="cnn" src="../../../_images/fig21.png" /></p>
<p>The number of skip blocks and the number of filters used in each one is set by the ‘filters’ list argument - one skip block will be created for each element in the list.</p>
</div>
</div>
<div class="section" id="implementing-the-design">
<h1>Implementing the Design<a class="headerlink" href="#implementing-the-design" title="Permalink to this headline">¶</a></h1>
<p>This section will lead you through the steps necessary to run the design in hardware.</p>
<div class="section" id="preparing-the-host-machine-and-target-boards">
<h2>Preparing the Host Machine and Target Boards<a class="headerlink" href="#preparing-the-host-machine-and-target-boards" title="Permalink to this headline">¶</a></h2>
<p>The host machine has several requirements that need to be met before we begin. You will need:</p>
<ul class="simple">
<li><p>An x86 host machine with that meets the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/blob/master/doc/system_requirements">sytem requirements</a> and internet access to download files.</p></li>
<li><p>Optionally, a GPU card suitable for training (a trained checkpoint is provided for those who wish to skip the training step).</p></li>
<li><p>You should follow the host and target setup instructions provided in <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/tree/master/VART#quick-start-for-edge">Quick Start for Edge</a> and in <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/tree/master/alveo-hbm#dpucahx8h----the-dpu-for-alveo-accelerator-card-with-hbm">Alveo card setup</a>.  Ignore the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/tree/master/alveo-hbm#dpucahx8h----the-dpu-for-alveo-accelerator-card-with-hbm">DPUCAHX8H Overlays Setup</a> section as we will run that as part of this tutorial.</p></li>
</ul>
<p>For more details, refer to the latest version of the <em>Vitis AI User Guide</em> (<a class="reference external" href="https://www.xilinx.com/html_docs/vitis_ai/1_2/zkj1576857115470.html">UG1414</a>).</p>
</div>
<div class="section" id="downloading-the-design-and-setting-up-the-workspace">
<h2>Downloading the Design and Setting up the Workspace<a class="headerlink" href="#downloading-the-design-and-setting-up-the-workspace" title="Permalink to this headline">¶</a></h2>
<p>This repository should be downloaded to the host machine as a zip file and then unzipped to a folder, or cloned using the <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span></code> command from a terminal.</p>
<p>Note that each Vitis-AI tutorial is provided as a separate git branch, so the clone command should specify the correct branch and the target folder you want to clone to:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span> git clone -b Moving-Edge-Cloud https://github.com/Xilinx/Vitis-AI-Tutorials.git &lt;target_folder_path&gt;
</pre></div>
</div>
<p>Download the <a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/data">Kaggle dog-vs-cats dataset</a> - note that you will need to register and create an account on the Kaggle website  before being able to download the dataset.</p>
<p>Move the downloaded dogs-vs-cats.zip file into the ‘files’ folder of the design repository (i.e the same folder as the python (.py) and shell (.sh) scripts).</p>
<p>Open a linux terminal, cd into the repository folder then into the ‘files’ folder. Start the Vitis AI docker - if you have a GPU in the host system, it is recommended that you use the GPU version of the docker container. If you intend running the model training, you will definitely need the GPU docker container. If you are going to skip the training phase, then the CPU docker container will be sufficient:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># navigate to densenet tutorial folder</span>
<span class="nb">cd</span> &lt;path_to_densenet_design&gt;/files

<span class="c1"># to start GPU docker</span>
<span class="nb">source</span> ./start_gpu_docker.sh

<span class="c1"># ..or to start CPU docker</span>
<span class="nb">source</span> ./start_cpu_docker.sh
</pre></div>
</div>
<p>The docker container will start and you should see something like this in the terminal:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">==========================================</span>
__      ___ _   _                   _____
<span class="se">\ \ </span>   / <span class="o">(</span>_<span class="o">)</span> <span class="p">|</span> <span class="o">(</span>_<span class="o">)</span>            /<span class="se">\ </span>  <span class="p">|</span>_   _<span class="p">|</span>
 <span class="se">\ \ </span> / / _<span class="p">|</span> <span class="p">|</span>_ _ ___ ______ /  <span class="se">\ </span>   <span class="p">|</span> <span class="p">|</span>  
  <span class="se">\ \/</span> / <span class="p">|</span> <span class="p">|</span> __<span class="p">|</span> / __<span class="p">|</span>______/ /<span class="se">\ \ </span>  <span class="p">|</span> <span class="p">|</span>  
   <span class="se">\ </span> /  <span class="p">|</span> <span class="p">|</span> <span class="p">|</span>_<span class="p">|</span> <span class="se">\_</span>_ <span class="se">\ </span>    / ____ <span class="se">\ </span>_<span class="p">|</span> <span class="p">|</span>_
    <span class="se">\/</span>   <span class="p">|</span>_<span class="p">|</span><span class="se">\_</span>_<span class="p">|</span>_<span class="p">|</span>___/    /_/    <span class="se">\_\_</span>____<span class="p">|</span>

<span class="o">==========================================</span>

Docker Image Version: latest
Build Date: Wed Apr <span class="m">15</span> <span class="m">11</span>:01:32 CEST <span class="m">2020</span>
<span class="nv">VAI_ROOT</span><span class="o">=</span>/opt/vitis_ai
For TensorFlow Workflows <span class="k">do</span>:
  conda activate vitis-ai-tensorflow
For Caffe Workflows <span class="k">do</span>:
  conda activate vitis-ai-caffe
For Neptune Workflows <span class="k">do</span>:
  conda activate vitis-ai-neptune
mharvey@XITMHARVEY33:/workspace$
</pre></div>
</div>
<blockquote>
<div><p>:bulb: If you get a “Permission Denied” error when running the start_gpu_docker.sh or start_cpu_docker.sh scripts, it is almost certainly because the docker_run.sh script is not set to be executable. You can fix this by running the following command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>chmod +x ./docker_run.sh
</pre></div>
</div>
</div></blockquote>
<p>Now run the environment setup script:  <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./0_setenv.sh</span></code></p>
<p>This will set up all the environment variables (..mainly pointers to folder and files..) most of which users can edit as required. It will also create the folders for the logs and the trained keras checkpoint.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">0_setenv.sh</span> <span class="pre">script</span></code> also activates the ‘vitis-ai-tensorflow’ TensorFlow conda environment, so you should now see that the terminal prompt looks like this:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>vitis-ai-tensorflow<span class="o">)</span> mharvey@XITMHARVEY33:/workspace$
</pre></div>
</div>
</div>
<div class="section" id="step-1-arranging-the-dataset">
<h2>Step 1 - Arranging the Dataset<a class="headerlink" href="#step-1-arranging-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>To run step 1: <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./1_create_datasets.sh</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">1_create_datasets.sh</span></code> shell script calls the <code class="docutils literal notranslate"><span class="pre">create_datasets.py</span></code> Python script which will unzip the downloaded dogs-vs-cats archive, create the necessary folders and then split the files into the train, validation or test datasets based on a 70:20:10 split. The files are randomly shuffled before being split into the datasets.</p>
<p>The create_datasets.py scripts has four command line arguments:</p>
<p>| Argument                  | Type     | Default value     | Description                                                    |<br />| ————————- | ———|:—————–:| —————————————————————|<br />| <code class="docutils literal notranslate"><span class="pre">--dataset_dir</span></code>  or <code class="docutils literal notranslate"><span class="pre">-d</span></code>  | string   |   ./dataset       | The path to the dataset root folder                            |<br />| <code class="docutils literal notranslate"><span class="pre">--overwrite</span></code>    or <code class="docutils literal notranslate"><span class="pre">-o</span></code>  | string   |   true            | true - always create a new dataset                             |<br />|                           |          |                   | false - only create a new dataset if it doesn’t already exist  |<br />| <code class="docutils literal notranslate"><span class="pre">--input_height</span></code> or <code class="docutils literal notranslate"><span class="pre">-ih</span></code> | integer  |   200             | Input images will be resized to this height (pixels)           |<br />| <code class="docutils literal notranslate"><span class="pre">--input_width</span> </code> or <code class="docutils literal notranslate"><span class="pre">-iw</span></code> | integer  |   250             | Input images will be resized to this width (pixels)            |</p>
<p><strong>Note</strong>: The image resizing could also have been done on-the-fly as part of the Keras image augmentation - this however slows down training considerably, so resizing has been implemented as a run-only-once part of the dataset preparation.</p>
</div>
<div class="section" id="step-2-training">
<h2>Step 2 - Training<a class="headerlink" href="#step-2-training" title="Permalink to this headline">¶</a></h2>
<p>Training takes a considerable time, between 8-12 hours depending on the GPU. Users can either:</p>
<ul class="simple">
<li><p>Reduce the number of epochs by editing the <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">EPOCHS=180</span></code> line in the <code class="docutils literal notranslate"><span class="pre">0_setenv.sh</span></code> shell script. Obviously, less epochs of training will have a negative impact on the final accuracy.</p></li>
<li><p>Skip the training phase altogether and use the pretrained Keras checkpoint available in the pretrained/keras_model.zip archive. The k_model.h5 file inside this zip archive should be copied to the ./files/build/keras_model folder and the remaining parts of Step 1 should be skipped and users should go direct to Step 2.</p></li>
<li><p>Depending on how much memory your GPU card has, it may be necessary to modify the <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">BATCHSIZE=80</span></code> line in the <code class="docutils literal notranslate"><span class="pre">0_setenv.sh</span></code> shell script. If you run out of memory during training, then try reducing it.</p></li>
</ul>
<p>To run step 2: <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./2_train.sh</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">./2_train.sh</span></code> shell script calls the <code class="docutils literal notranslate"><span class="pre">train.py</span></code> script which executes the training, evaluation and prediction accuracy testing and uses some advanced features of Keras:</p>
<ul class="simple">
<li><p>Images are read from disk using the flow_from_directory() method.</p></li>
<li><p>On-the-fly image augmentation is used:</p>
<ul>
<li><p>Normalization of pixel values from 0:255 to 0:1</p></li>
<li><p>Random flipping along the vertical axis.</p></li>
<li><p>Random vertical and horizontal shifts.</p></li>
<li><p>Shuffling of the images between epochs.</p></li>
</ul>
</li>
<li><p>The weights &amp; biases from the epoch with the best validation accuracy are automatically saved in the Keras HDF5 checkpoint.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">train.py</span></code> has several command line arguments:</p>
<p>| Argument                  | Type     | Default value     | Description                                |<br />| ————————- | ———|:—————–:| ——————————————-|<br />| <code class="docutils literal notranslate"><span class="pre">--input_height</span></code> or <code class="docutils literal notranslate"><span class="pre">-ih</span></code> | integer  |   200             | Height in pixels of input images           |<br />| <code class="docutils literal notranslate"><span class="pre">--input_width</span> </code> or <code class="docutils literal notranslate"><span class="pre">-iw</span></code> | integer  |   250             | Width in pixels of input images            |<br />| <code class="docutils literal notranslate"><span class="pre">--input_chan</span>&#160; </code> or <code class="docutils literal notranslate"><span class="pre">-ic</span></code> | integer  |   3               | Number of channels in input image          |<br />| <code class="docutils literal notranslate"><span class="pre">--dataset</span></code>      or <code class="docutils literal notranslate"><span class="pre">-d</span></code>  | string   |   ./dataset       | The path to the dataset root folder        |<br />| <code class="docutils literal notranslate"><span class="pre">--batchsize</span></code>    or <code class="docutils literal notranslate"><span class="pre">-b</span></code>  | integer  |   25              | The training data batchsize                |<br />| <code class="docutils literal notranslate"><span class="pre">--learnrate</span></code>    or <code class="docutils literal notranslate"><span class="pre">-lr</span></code> | float    |   0.0001          | The learning rate used by the optimizer    |<br />| <code class="docutils literal notranslate"><span class="pre">--epochs</span></code>       or <code class="docutils literal notranslate"><span class="pre">-e</span></code>  | integer  |   100             | The number of training epochs              |<br />| <code class="docutils literal notranslate"><span class="pre">--keras_json</span>&#160; </code> or <code class="docutils literal notranslate"><span class="pre">-kj</span></code> | string   |   None            | path to JSON file for saving Keras model   |
| <code class="docutils literal notranslate"><span class="pre">--keras_hdf5</span>&#160; </code> or <code class="docutils literal notranslate"><span class="pre">-kh</span></code> | string   |   ./model.hdf5    | path to HDF5 file for saving Keras model   |
| <code class="docutils literal notranslate"><span class="pre">--aug</span></code>          or <code class="docutils literal notranslate"><span class="pre">-a</span></code>  | string   |   None            | path to folder for saving augmented images |
| <code class="docutils literal notranslate"><span class="pre">--tboard</span></code>       or <code class="docutils literal notranslate"><span class="pre">-tb</span></code> | string   |   ./tb_logs       | path to folder for saving TensorBoard data |</p>
<p>After training has finished, the trained Keras checkpoint will be found in the ./files/build/keras_model folder as an HDF5 file called k_model.h5.</p>
<p><strong>Note</strong>: Any error messages relating to CUPTI can safely be ignored.</p>
</div>
<div class="section" id="step-3-convert-the-keras-hdf5-checkpoint-to-a-tensorflow-frozen-graph">
<h2>Step 3 - Convert the Keras HDF5 Checkpoint to a TensorFlow Frozen Graph<a class="headerlink" href="#step-3-convert-the-keras-hdf5-checkpoint-to-a-tensorflow-frozen-graph" title="Permalink to this headline">¶</a></h2>
<p>To run step 3: <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./3_keras2tf.sh</span></code></p>
<p>The Vitis AI tools cannot operate directly on Keras checkpoints and require a TensorFlow compatible frozen graph as the input format. The <code class="docutils literal notranslate"><span class="pre">3_keras2tf.sh</span></code> shell script will create the frozen graph in two steps:</p>
<ol class="simple">
<li><p>The HDF5 file is converted to a TensorFlow checkpoint.</p></li>
<li><p>The TensorFlow checkpoint is converted to a ‘frozen graph’ in binary protobuf format.</p></li>
</ol>
<p>The output .pb file is generally known as a ‘frozen graph’ since all variables are converted into constants and graph nodes associated with training such as the optimizer and loss functions are stripped out.</p>
<p>After this step is completed, there should be a protobuf file called ‘frozen_graph.pb’ in the ./files/build/freeze folder.</p>
</div>
<div class="section" id="step-4-evaluate-the-frozen-graph">
<h2>Step 4 - Evaluate the Frozen Graph<a class="headerlink" href="#step-4-evaluate-the-frozen-graph" title="Permalink to this headline">¶</a></h2>
<p>To run step 4: <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./4_eval_frozen.sh</span></code></p>
<p>This is an optional step as the frozen graph is still in floating-point format and should give almost identical accuracy results as the evaluation done during the training phase (step 1). All images of the test set are passed through the frozen model and the accuracy is calculated.</p>
</div>
<div class="section" id="step-5-quantize-the-frozen-graph">
<h2>Step 5 - Quantize the Frozen Graph<a class="headerlink" href="#step-5-quantize-the-frozen-graph" title="Permalink to this headline">¶</a></h2>
<p>To run step 5: <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./5_quant.sh</span></code></p>
<p>The DPU accelerator IP executes all calculations in 8bit integer format, so we must quantize our floating-point frozen graph. This is done by the Vitis AI tools, in particular by the ‘vai_q_tensorflow quantize’ command. This command can be seen in the <code class="docutils literal notranslate"><span class="pre">5_quant.sh</span></code> script and has several arguments that we must provide values for:</p>
<p>| Argument              | Description                                                    |
|———————- | ————————————————————– |
|<code class="docutils literal notranslate"><span class="pre">--input_frozen_graph</span></code> | path and name of the input  .pb frozen graph                   |
|<code class="docutils literal notranslate"><span class="pre">--input_fn</span></code>           | Name of input function used in calibration pre-processing      |
|<code class="docutils literal notranslate"><span class="pre">--output_dir</span></code>         | Name of the output folder where the quantized models are saved |
|<code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code>        | Name(s) of the input nodes                                     |
|<code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>       | Name(s) of the output nodes                                    |
|<code class="docutils literal notranslate"><span class="pre">--input_shapes</span></code>       | Shape(s) of the input nodes                                    |
|<code class="docutils literal notranslate"><span class="pre">--calib_iter</span></code>         | Number of calibration iterations                               |</p>
<p><strong>Note</strong>: Any error messages relating to ./bin/ptxas can be ignored.</p>
<p>Most of the arguments are self-explanatory but special mention needs to be made of –input_fn and –calib_iter.</p>
<p>We require a sample set of data to calibrate the quantization process. This data will be passed through the model and so must be pre-processed in exactly the same way as the data is pre-processed in training…the function pointed to by the –input_fn argument will need to contain all of the pre-processing steps.</p>
<p>A random list of images from the training set to be used for the calibration is created by the <code class="docutils literal notranslate"><span class="pre">make_calib_list.py</span></code> python script</p>
<p>The image_input_fn.py Python script contains a single function called calib_input (..hence we set –input_fn to image_input_fn.calib_input in the <code class="docutils literal notranslate"><span class="pre">5_quant.sh</span></code> shell script..) which opens the images with OpenCV, flips them to RGB from BGR as the model was trained on RGB images and then normalizes them to have all pixels in the range 0 to 1.0, exactly as was done in training and evaluation.</p>
<p>The number of images generated for use in calibration is set by the CALIB_IMAGES environment variable in the <code class="docutils literal notranslate"><span class="pre">0_setenv.sh</span></code> script. Care should be taken that the number of calibration iterations (–calib_iter) multiplied by the calibration batch size (set in the image_input_fn.py script) does not exceed the total number of available images (CALIB_IMAGES).</p>
<p>Once quantization has completed, we will have the quantized deployment model (deploy_model.pb) and the evaluation model (quantize_eval_model.pb) in the ./files/build/quantize folder.</p>
</div>
<div class="section" id="step-6-evaluate-the-quantized-model">
<h2>Step 6 - Evaluate the Quantized Model<a class="headerlink" href="#step-6-evaluate-the-quantized-model" title="Permalink to this headline">¶</a></h2>
<p>To run step 6: <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./6_eval_quant.sh</span></code></p>
<p>This is an optional, but <em>highly</em> recommended step. The conversion from a floating-point model where the values can have a very wide dynamic range to an 8bit model where values can only have one of 256 values almost inevitably leads to a small loss of accuracy. We use the quantized evaluation model to see exactly how much impact the quantization process has had.</p>
<p>The exact same Python script, eval_graph.py, that was used to evaluate the frozen graph is used to evaluate the quantized model.</p>
</div>
<div class="section" id="step-7-compile-the-quantized-model">
<h2>Step 7 - Compile the Quantized Model<a class="headerlink" href="#step-7-compile-the-quantized-model" title="Permalink to this headline">¶</a></h2>
<p>To run step 7: <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./7_compile_zcu102.sh</span></code> or <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./7_compile_u50.sh</span></code></p>
<p>The DPUCZDX8G (for Zynq) and DPUCAHX8H (for Alveo U50) are soft-core IPs whose only function is to accelerate the execution of convolutional neural networks. They are co-processors with their own instruction sets - those instructions are passed to the DPUCZDX8G in .elf file format or in .xmodel format to the DPUCAHX8H.</p>
<p>The Vitis AI compiler will convert, and optimize where possible, the quantized model to a set of micro-instructions and then output them to either .elf or .xmodel files depending on the value of the –arch argument passed to the vai_c_tensorflow command.</p>
<p>Note that the input graph to the two compile commands is different. For the Zynq DPUCZDX8G it is deploy_model.pb and for the Alveo DPUCAHX8H it is quantize_eval_model.pb.</p>
</div>
<div class="section" id="step-8-run-the-application-on-the-target-board">
<h2>Step 8 - Run the Application on the Target Board<a class="headerlink" href="#step-8-run-the-application-on-the-target-board" title="Permalink to this headline">¶</a></h2>
<div class="section" id="for-zcu102">
<h3>For ZCU102:<a class="headerlink" href="#for-zcu102" title="Permalink to this headline">¶</a></h3>
<p>To run step 8: <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./8_make_target_zcu102.sh</span></code></p>
<p>This final step will copy all the required files for running on the board into the ./files/build/target_zcu102 folder. The entire target_zcu102 folder will need to be copied to the ZCU102 SDcard. The <code class="docutils literal notranslate"><span class="pre">8_make_target_zcu102.sh</span></code> script also copies the test set images to target_zcu102/images - the application code will preprocess and classify these images.</p>
<p>Copy it to the /home/root folder of the flashed SD card, this can be done in one of several ways:</p>
<ol class="simple">
<li><p>Direct copy to SD Card:</p></li>
</ol>
<ul class="simple">
<li><p>If the host machine has an SD card slot, insert the flashed SD card and when it is recognised you will see two volumes, BOOT and ROOTFS. Navigate into the ROOTFS and then into the /home folder.  Make the ./root folder writeable by issuing the command <code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">chmod</span> <span class="pre">-R</span> <span class="pre">777</span> <span class="pre">root</span></code> and then copy the entire target folder from the host machine into the /home/root folder of the SD card.</p></li>
<li><p>Unmount both the BOOT and ROOTFS volumes from the host machine and then eject the SD Card from the host machine.</p></li>
</ul>
<ol class="simple">
<li><p>With scp command:</p></li>
</ol>
<ul class="simple">
<li><p>If the ZCU102 is connected to a network and reachable by the host machine, the target folder can be copied using scp. If you connect directly from your host machine to the ZCU102 using ethernet, you may need to set up static IP addresses.</p></li>
<li><p>The command will be something like <code class="docutils literal notranslate"><span class="pre">scp</span> <span class="pre">-r</span> <span class="pre">./build/target_zcu102</span> <span class="pre">root&#64;192.168.1.227:~/.</span></code>  assuming that the ZCU102 IP address is 192.168.1.227 - adjust this and the path to the target folder as appropriate for your system.</p></li>
<li><p>If the password is asked for, insert ‘root’.</p></li>
</ul>
<p>With the target folder copied to the SD Card and the ZCU102 booted, you can issue the command for launching the application - note that this done on the ZCU102 board, not the host machine, so it requires a connection to the ZCU102 such as a serial connection to the UART or an SSH connection via Ethernet.</p>
<p>The application can be started by navigating into the target_zcu102 folder (<code class="docutils literal notranslate"><span class="pre">cd</span> <span class="pre">target_zcu102</span></code>) and then issuing the command <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">app_mt.py</span> <span class="pre">-m</span> <span class="pre">model_dir/dpu_customcnn.elf</span></code>. The application will start and after a few seconds will show the throughput (in frames/sec) and the accuracy:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ python3 app_mt.py -m model_dir/dpu_customcnn.elf
----------------------------
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">1</span>
 --model     :  model_dir/dpu_customcnn.elf
----------------------------
Pre-processing <span class="m">2500</span> images...
Starting <span class="m">1</span> threads...
<span class="nv">FPS</span><span class="o">=</span><span class="m">191</span>.86, total <span class="nv">frames</span> <span class="o">=</span> <span class="m">2500</span> , <span class="nv">time</span><span class="o">=</span><span class="m">13</span>.0301 seconds
Correct: <span class="m">2426</span> Wrong: <span class="m">74</span> Accuracy: <span class="m">0</span>.9704
</pre></div>
</div>
<p>For better throughput, the number of threads can be increased like this:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ python3 app_mt.py -t <span class="m">8</span> -m model_dir/dpu_customcnn.elf
----------------------------
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">8</span>
 --model     :  model_dir/dpu_customcnn.elf
----------------------------
Pre-processing <span class="m">2500</span> images...
Starting <span class="m">8</span> threads...
<span class="nv">FPS</span><span class="o">=</span><span class="m">694</span>.47, total <span class="nv">frames</span> <span class="o">=</span> <span class="m">2500</span> , <span class="nv">time</span><span class="o">=</span><span class="m">3</span>.5998 seconds
Correct: <span class="m">2426</span> Wrong: <span class="m">74</span> Accuracy: <span class="m">0</span>.9704
</pre></div>
</div>
</div>
<div class="section" id="for-alveo-u50">
<h3>For Alveo U50:<a class="headerlink" href="#for-alveo-u50" title="Permalink to this headline">¶</a></h3>
<p>This final step will copy all the required files for running on the board into the ./files/build/target_u50 folder. Note that these steps need to be run from inside of the Vitis AI Docker container.</p>
<p>To run step 8: <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">./8_make_target_u50.sh</span></code> and then follow the extra steps outlined below.</p>
<p>Run the <code class="docutils literal notranslate"><span class="pre">U50_overlay.sh</span></code> script (internet connection required) to download and install the correct overlay (note that the U50 will need to have been flashed with correct deployment shell - this should have been done in the ‘Preparing the host machine and target boards’ section above). The complete steps to run on the Alveo U50 are as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span> ./U50_overlay.sh
<span class="nb">cd</span> ./build/target_u50
/usr/bin/python3 app_mt.py -m model_dir/customcnn.xmodel
</pre></div>
</div>
<p>You should see something like this:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>mharvey@XITMHARVEY33:/workspace/build/target_u50$ /usr/bin/python3 app_mt.py -m model_dir/customcnn.xmodel
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">1</span>
 --model     :  model_dir/customcnn.xmodel
Pre-processing <span class="m">2500</span> images...
Starting <span class="m">1</span> threads...
<span class="nv">FPS</span><span class="o">=</span><span class="m">509</span>.50, total <span class="nv">frames</span> <span class="o">=</span> <span class="m">2500</span> , <span class="nv">time</span><span class="o">=</span><span class="m">4</span>.9068 seconds
Correct: <span class="m">2426</span> Wrong: <span class="m">74</span> Accuracy: <span class="m">0</span>.9704
</pre></div>
</div>
<p>Similar to the ZCU102, the number of threads can be increased for higher throughput:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>mharvey@XITMHARVEY33:/workspace/build/target_u50$ /usr/bin/python3 app_mt.py -m model_dir/customcnn.xmodel -t <span class="m">8</span>
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">8</span>
 --model     :  model_dir/customcnn.xmodel
Pre-processing <span class="m">2500</span> images...
Starting <span class="m">8</span> threads...
<span class="nv">FPS</span><span class="o">=</span><span class="m">2507</span>.25, total <span class="nv">frames</span> <span class="o">=</span> <span class="m">2500</span> , <span class="nv">time</span><span class="o">=</span><span class="m">0</span>.9971 seconds
Correct: <span class="m">2426</span> Wrong: <span class="m">74</span> Accuracy: <span class="m">0</span>.9704
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p><a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats">Kaggle dogs-vs-cats competition.</a></p></li>
</ol>
<!--Edited 7/29--></div>


           </div>
           
          </div>
          <footer>
<!-- Atalwar: Moved the footer code to layout.html to resolve conflict with the Xilinx template -->
</footer>

        </div>
      </div>


	  <!-- Sphinx Page Footer block -->
  

  <hr/>

  <div role="contentinfo" class="copyright">
    <p class="footerinfo">

    </p>
	<br>
  </div>
      </div>
    </section>


  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

   <script type="text/javascript">
    jQuery(function() { Search.loadIndex("searchindex.js"); });
  </script>

  <script type="text/javascript" id="searchindexloader"></script>


  
  
    
  



  <!--  Xilinx template footer block -->
							</div>
						</div>
					</div>
				</div>
				<div class="xilinxExperienceFragments experiencefragment aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
					<div class="xf-content-height">
						<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 ">
							<div class="footer parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
								<noindex>
                  <!-- make footer fixed - NileshP -->
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
                  <!-- make footer fixed NileshP-->
									<footer>
										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">
													<div class="row">
														<div class="footerSocial parbase">
															<div class="col-md-push-6 col-lg-push-6 col-md-6 col-lg-6">
																<ul class="list-inline pull-right social-menu">
																	<li>
																		<a href="https://www.linkedin.com/company/xilinx">
																		<span class="linkedin icon"></span>
																		<span class="sr-only">Connect on LinkedIn</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.twitter.com/XilinxInc">
																		<span class="twitter icon"></span>
																		<span class="sr-only">Follow us on Twitter</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.facebook.com/XilinxInc">
																		<span class="facebook icon"></span>
																		<span class="sr-only">Connect on Facebook</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.youtube.com/XilinxInc">
																		<span class="youtube icon"></span>
																		<span class="sr-only">Watch us on YouTube</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.xilinx.com/registration/subscriber-signup.html">
																		<span class="newsletter icon"></span>
																		<span class="sr-only">Subscribe to Newsletter</span>
																		</a>
																	</li>
																</ul>
															</div>
														</div>
														<div class="col-md-pull-6 col-lg-pull-6 col-md-6 col-lg-6">
															<span class="copyright">
                                  
                                  &copy; 2020–2021, Xilinx, Inc.
                              </span>
															<ul class="list-inline sub-menu">
																<li>
																	<a href="https://www.xilinx.com/about/privacy-policy.html">Privacy</a>
																</li>
																<li>
																	<a href="https://www.xilinx.com/about/legal.html">Legal</a>
																</li>
																<li>
																	<a href="https://www.xilinx.com/about/contact.html">Contact</a>
																</li>
															</ul>
														</div>
													</div>
												</div>
											</div>
										</div>
									</footer>
								</noindex>
							</div>
						</div>
					</div>
				</div>
				<div class="quicklinks parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
					<noindex>
						<span class="quickLinks">
							<ul>
								<li>
									<a href="#top" class="btn backToTop">
									<span class="fas fa-angle-up" aria-hidden="true"></span>
									</a>
								</li>
							</ul>
						</span>
					</noindex>
				</div>
			</div>
		</div>
		<script>window.CQ = window.CQ || {}</script>
		<script src="https://static.cloud.coveo.com/searchui/v2.4382/js/CoveoJsSearch.Lazy.min.js"></script>
		<script>
			var underscoreSetup = function () {
			  _.templateSettings.interpolate = /\{\{=([^-][\S\s]+?)\}\}/g;
			  _.templateSettings.evaluate = /\{\{([^-=][\S\s]+?)\}\}/g;
			  _.templateSettings.escape = /\{\{-([^=][\S\s]+?)\}\}/g;
			}

			underscoreSetup();
		</script>
	</body>
</html>